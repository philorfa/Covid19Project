{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pso_xception.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfoYJYEfF09m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "e9883560-603f-463e-f6f7-e18c88273486"
      },
      "source": [
        "!pip install --upgrade pyswarm\n",
        "!pip install pymc3\n",
        "!pip install --upgrade pactools"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pyswarm in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from pyswarm) (1.18.5)\n",
            "Requirement already satisfied: pymc3 in /usr/local/lib/python3.6/dist-packages (3.7)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from pymc3) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pymc3) (1.0.5)\n",
            "Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.6/dist-packages (from pymc3) (4.41.1)\n",
            "Requirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from pymc3) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from pymc3) (1.4.1)\n",
            "Requirement already satisfied: theano>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from pymc3) (1.0.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pymc3) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pymc3) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pymc3) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py>=2.7.0->pymc3) (1.15.0)\n",
            "Requirement already up-to-date: pactools in /usr/local/lib/python3.6/dist-packages (0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlC6l-CxGQco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "4614701e-beae-4e76-8cff-a5ce9d7b29c3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from pyswarm import pso\n",
        "from os import path\n",
        "import os\n",
        "import requests\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "import numpy\n",
        "import sys\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from numpy import array\n",
        "from numpy.random import choice\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import statistics\n",
        "import pandas\n",
        "import math\n",
        "import csv\n",
        "import random\n",
        "import logging\n",
        "from pymc3 import *\n",
        "import pymc3 as pm\n",
        "from functools import reduce\n",
        "from operator import add\n",
        "from tqdm import tqdm\n",
        "import geopy.distance\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from theano import shared\n",
        "from sklearn import preprocessing\n",
        "print('Running on PyMC3 v{}'.format(pm.__version__))\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "#TESNORFOW\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import datasets, layers, models\n",
        "\n",
        "#KERAS LIBRARIES\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Dropout , Flatten,BatchNormalization,Conv2D,MaxPooling2D, Activation,LSTM,Embedding,Input,GlobalAveragePooling2D\n",
        "from keras.regularizers import l1, l2, l1_l2\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend \n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import skimage.transform\n",
        "\n",
        "from numpy import savetxt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on PyMC3 v3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA1-cz1EKWwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data2():\n",
        "  train1 = np.load('/content/drive/My Drive/NumpyArrayCovidx/train.npy',allow_pickle=True)\n",
        "  train_labels1 = np.load('/content/drive/My Drive/NumpyArrayCovidx/train_labels.npy',allow_pickle=True)\n",
        "  \n",
        "  train4=np.empty([20260, 72,72,3], dtype=int)\n",
        "  \n",
        "  for i in range(len(train1)):\n",
        "    train4[i] = skimage.transform.resize(train1[i], (72, 72))\n",
        "  \n",
        "  train2,test1, train_labels2,test_labels1 = train_test_split(train4, train_labels1, test_size=0.2, random_state=42)\n",
        "  \n",
        "  x_train=train2/225.0\n",
        "  y_train = pd.get_dummies(train_labels2)\n",
        "\n",
        "  x_test=test1/225.0\n",
        "  y_test = pd.get_dummies(test_labels1)\n",
        "  return x_train,y_train,x_test,y_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etm4UNFMKTi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_test, y_test = data2()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJtUPq4_JGPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE2=(72,72,3) \n",
        "\n",
        "xception=keras.applications.xception.Xception(input_shape=IMG_SHAPE2,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3la_FcwJL6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fine_tuning,flatvsglobalpool,dense_layers,dropout1,dropout2\n",
        "lb=[0,0,0,0,0,0.001]\n",
        "ub=[150,1,3,0.65,0.65,0.2]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46l0K-ODJQmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_dense_xception(x):\n",
        "  print(x[0],x[1],x[2],x[3],x[4],x[5]) \n",
        "  IMG_SHAPE2=(72,72,3) \n",
        "\n",
        "  xception=keras.applications.xception.Xception(input_shape=IMG_SHAPE2,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "  tempex=xception\n",
        "  for layer in tempex.layers[:(-1)*int(round(x[0]))]:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  #vgg19.trainable=False\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tempex)\n",
        "  if (int(round(x[1]))):\n",
        "    model.add(keras.layers.Flatten())\n",
        "  else:\n",
        "    model.add(keras.layers.GlobalAveragePooling2D())\n",
        "  if (int(round(x[2]))==3):\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "    model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(x[3]))\n",
        "    model.add(keras.layers.Dense(32, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(x[4]))\n",
        "  elif (int(round(x[2]))==2):\n",
        "    model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(x[3]))\n",
        "    model.add(keras.layers.Dense(32, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(x[4]))\n",
        "  elif (int(round(x[2]))==1):\n",
        "    model.add(keras.layers.Dense(32, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(x[3]))\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  for layer in model.layers:\n",
        "    print(layer, layer.trainable)\n",
        "  model.add(keras.layers.Dense(3,activation=\"softmax\"))\n",
        "  if x[5]< 0.003:\n",
        "    learning_rate = 0.001\n",
        "  elif x[5]< 0.0075:\n",
        "    learning_rate = 0.005\n",
        "  elif x[5]< 0.015:\n",
        "    learning_rate = 0.01\n",
        "  elif x[5]< 0.035:\n",
        "    learning_rate = 0.02\n",
        "  elif x[5]< 0.075:\n",
        "    learning_rate = 0.05\n",
        "  elif x[5]< 0.125:\n",
        "    learning_rate = 0.1\n",
        "  elif x[5]< 0.175:\n",
        "    learning_rate = 0.15\n",
        "  else:\n",
        "    learning_rate = 0.2\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61QOmmYPJdxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EarlyStopper = EarlyStopping(patience=4, monitor='val_loss', mode='min')\n",
        "count=0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37mDYo0MJgMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apple(x):\n",
        "  model = create_model_dense_xception(x)\n",
        "  model.fit(x_train, y_train, epochs=20, batch_size=1000, verbose=1,validation_data=(x_test, y_test),callbacks=[EarlyStopper])\n",
        "  loss, acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "  if acc>0.9:\n",
        "    global count \n",
        "    count = count+1\n",
        "    model.save(f\"/content/drive/My Drive/saved_models/pso_xception/model-{count}-{round(acc, 3)}-{round(loss, 3)}\")\n",
        "    savetxt(f\"/content/drive/My Drive/saved_models/pso_xception/data-{count}.csv\", x, delimiter=',')\n",
        "  return loss  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-My1wOaeJicP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f69d2e86-c518-44bb-c64e-7757699ce78a"
      },
      "source": [
        "xopt, fopt = pso(apple, lb, ub, swarmsize=10, omega=0.5, phip=0.5, phig=1.0, maxiter=30, minstep=1)\n",
        "print (\"Best position\"+str(xopt))\n",
        "print (\"Loss:\" + str(fopt))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30.97718043003393 0.7769346036707678 1.5516341056368694 0.09257584416659673 0.07891045742432919 0.12469511389868054\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7fa255668320> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7fa255627278> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fa255627400> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7fa255458400> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fa255463c50> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7fa255473fd0> True\n",
            "Epoch 1/20\n",
            "17/17 [==============================] - 9s 537ms/step - loss: 0.7804 - accuracy: 0.6608 - val_loss: 9.2543 - val_accuracy: 0.4941\n",
            "Epoch 2/20\n",
            "17/17 [==============================] - 8s 444ms/step - loss: 0.3266 - accuracy: 0.8885 - val_loss: 3.8109 - val_accuracy: 0.6868\n",
            "Epoch 3/20\n",
            "17/17 [==============================] - 8s 445ms/step - loss: 0.2213 - accuracy: 0.9227 - val_loss: 3.4833 - val_accuracy: 0.7527\n",
            "Epoch 4/20\n",
            "17/17 [==============================] - 8s 444ms/step - loss: 0.1393 - accuracy: 0.9485 - val_loss: 2.5517 - val_accuracy: 0.7498\n",
            "Epoch 5/20\n",
            "17/17 [==============================] - 8s 444ms/step - loss: 0.0880 - accuracy: 0.9695 - val_loss: 2.1693 - val_accuracy: 0.8021\n",
            "Epoch 6/20\n",
            "17/17 [==============================] - 8s 444ms/step - loss: 0.0723 - accuracy: 0.9738 - val_loss: 1.6278 - val_accuracy: 0.8171\n",
            "Epoch 7/20\n",
            "17/17 [==============================] - 8s 444ms/step - loss: 0.0482 - accuracy: 0.9831 - val_loss: 1.1752 - val_accuracy: 0.8559\n",
            "Epoch 8/20\n",
            "17/17 [==============================] - 8s 443ms/step - loss: 0.0424 - accuracy: 0.9855 - val_loss: 0.8012 - val_accuracy: 0.8823\n",
            "Epoch 9/20\n",
            "17/17 [==============================] - 8s 443ms/step - loss: 0.0295 - accuracy: 0.9904 - val_loss: 0.7222 - val_accuracy: 0.8838\n",
            "Epoch 10/20\n",
            "17/17 [==============================] - 8s 443ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.9273 - val_accuracy: 0.8690\n",
            "Epoch 11/20\n",
            "17/17 [==============================] - 8s 444ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 1.0142 - val_accuracy: 0.8677\n",
            "Epoch 12/20\n",
            "17/17 [==============================] - 8s 444ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.7947 - val_accuracy: 0.9013\n",
            "Epoch 13/20\n",
            "17/17 [==============================] - 8s 444ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.6862 - val_accuracy: 0.8991\n",
            "Epoch 14/20\n",
            "17/17 [==============================] - 8s 445ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.7739 - val_accuracy: 0.9028\n",
            "Epoch 15/20\n",
            "17/17 [==============================] - 8s 444ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.8187 - val_accuracy: 0.8961\n",
            "Epoch 16/20\n",
            "17/17 [==============================] - 8s 443ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.7267 - val_accuracy: 0.8904\n",
            "Epoch 17/20\n",
            "17/17 [==============================] - 8s 443ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.7824 - val_accuracy: 0.8963\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.7824 - accuracy: 0.8963\n",
            "50.66681439607255 0.8555215126127989 2.843212727819953 0.33540497102777417 0.06388325730011025 0.00519931764258624\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7fa2cd6a0518> True\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7fa2cd663390> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fa2cd6634e0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7fa2cd47bc88> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fa2cd402128> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7fa2cd40bfd0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fa2cd4154a8> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7fa2cd424668> True\n",
            "Epoch 1/20\n",
            "17/17 [==============================] - 10s 569ms/step - loss: 1.1003 - accuracy: 0.4520 - val_loss: 1.0407 - val_accuracy: 0.5077\n",
            "Epoch 2/20\n",
            "17/17 [==============================] - 9s 528ms/step - loss: 0.9793 - accuracy: 0.5689 - val_loss: 0.8664 - val_accuracy: 0.6441\n",
            "Epoch 3/20\n",
            "17/17 [==============================] - 9s 528ms/step - loss: 0.8142 - accuracy: 0.6500 - val_loss: 0.7977 - val_accuracy: 0.6454\n",
            "Epoch 4/20\n",
            "17/17 [==============================] - 9s 527ms/step - loss: 0.5804 - accuracy: 0.8321 - val_loss: 0.5117 - val_accuracy: 0.8006\n",
            "Epoch 5/20\n",
            "17/17 [==============================] - 9s 528ms/step - loss: 0.2956 - accuracy: 0.9010 - val_loss: 0.4897 - val_accuracy: 0.8593\n",
            "Epoch 6/20\n",
            " 7/17 [===========>..................] - ETA: 4s - loss: 0.2335 - accuracy: 0.9241"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
