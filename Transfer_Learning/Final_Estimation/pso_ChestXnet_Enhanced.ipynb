{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pso_ChestXnet_Enhanced.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KprwWRixQJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5ee172e-dfe6-42ef-d153-d40d4a3e33a8"
      },
      "source": [
        "!pip install --upgrade keras\n",
        "!pip install --upgrade matplotlib\n",
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade pandas\n",
        "!pip install --upgrade pactools\n",
        "!pip install --upgrade pyswarm\n",
        "!pip install pymc3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
            "Requirement already up-to-date: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Collecting numpy\n",
            "  Using cached https://files.pythonhosted.org/packages/b1/9a/7d474ba0860a41f771c9523d8c4ea56b084840b5ca4092d96bdee8a3b684/numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "Successfully installed numpy-1.19.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Using cached https://files.pythonhosted.org/packages/b3/a9/b1bc4c935ed063766bce7d3e8c7b20bd52e515ff1c732b02caacf7918e5a/numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.31.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Found existing installation: numpy 1.19.1\n",
            "    Uninstalling numpy-1.19.1:\n",
            "      Successfully uninstalled numpy-1.19.1\n",
            "Successfully installed numpy-1.18.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already up-to-date: pactools in /usr/local/lib/python3.6/dist-packages (0.3)\n",
            "Requirement already up-to-date: pyswarm in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from pyswarm) (1.18.5)\n",
            "Requirement already satisfied: pymc3 in /usr/local/lib/python3.6/dist-packages (3.7)\n",
            "Requirement already satisfied: theano>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from pymc3) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from pymc3) (1.18.5)\n",
            "Requirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from pymc3) (2.10.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pymc3) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.6/dist-packages (from pymc3) (4.41.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from pymc3) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pymc3) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from theano>=1.0.4->pymc3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pymc3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pymc3) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK9OmQFsx7Jw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "7cf64fb8-9653-44bb-9644-e312a08ea0f9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from pyswarm import pso\n",
        "from os import path\n",
        "import os\n",
        "import requests\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "import numpy\n",
        "import sys\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from numpy import array\n",
        "from numpy.random import choice\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import statistics\n",
        "import pandas\n",
        "import math\n",
        "import csv\n",
        "import random\n",
        "import logging\n",
        "from pymc3 import *\n",
        "import pymc3 as pm\n",
        "from functools import reduce\n",
        "from operator import add\n",
        "from tqdm import tqdm\n",
        "import geopy.distance\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from theano import shared\n",
        "from sklearn import preprocessing\n",
        "print('Running on PyMC3 v{}'.format(pm.__version__))\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "#TESNORFOW\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import datasets, layers, models\n",
        "\n",
        "#KERAS LIBRARIES\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Dropout , Flatten,BatchNormalization,Conv2D,MaxPooling2D, Activation,LSTM,Embedding,Input,GlobalAveragePooling2D\n",
        "from keras.regularizers import l1, l2, l1_l2\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend \n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import skimage.transform\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "from numpy import savetxt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on PyMC3 v3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPxDMpOA4NQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data1():\n",
        "  train1 = np.load('/content/drive/My Drive/NumpyArrayCovidx/train.npy',allow_pickle=True)\n",
        "  train_labels1 = np.load('/content/drive/My Drive/NumpyArrayCovidx/train_labels.npy',allow_pickle=True)\n",
        "  train2,test1, train_labels2,test_labels1 = train_test_split(train1, train_labels1, test_size=0.2,random_state=42)\n",
        "  x_train=train2/225.0\n",
        "  y_train = pd.get_dummies(train_labels2)\n",
        "\n",
        "  x_test=test1/225.0\n",
        "  y_test = pd.get_dummies(test_labels1)\n",
        "  return x_train,y_train,x_test,y_test\n",
        "\n",
        "def data():\n",
        "  test = np.load('/content/drive/My Drive/NumpyArrayCovidx/test.npy',allow_pickle=True)\n",
        "  test_labels = np.load('/content/drive/My Drive/NumpyArrayCovidx/test_labels.npy',allow_pickle=True)\n",
        "  \n",
        "  test64=test/225.0\n",
        "  return test64,test_labels"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGp3C8hUgnie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_test, y_test = data1()\n",
        "test64,test_labels=data()\n",
        "le = preprocessing.LabelEncoder()\n",
        "labels = le.fit_transform(test_labels)\n",
        "target_names = ['covid19', 'normal', 'pneumonia']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e55ICOPg1yPF",
        "colab_type": "text"
      },
      "source": [
        "###ChestXnet\n",
        "\n",
        "ChexNet is a deep learning algorithm that can detect and localize 14 kinds of diseases from chest X-ray images. As described in the paper, a 121-layer densely connected convolutional neural network is trained on ChestX-ray14 dataset, which contains 112,120 frontal view X-ray images from 30,805 unique patients.\n",
        "\n",
        "https://github.com/brucechou1983/CheXNet-Keras\n",
        "\n",
        "https://tinyurl.com/y8ezu5c9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr0-FVWJyB9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import importlib\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "class ModelFactory:\n",
        "    \"\"\"\n",
        "    Model facotry for Keras default models\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.models_ = dict(\n",
        "            DenseNet121=dict(\n",
        "                input_shape=(64, 64, 3),\n",
        "                module_name=\"densenet\",\n",
        "                last_conv_layer=\"bn\",\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def get_last_conv_layer(self, model_name):\n",
        "        return self.models_[model_name][\"last_conv_layer\"]\n",
        "\n",
        "    def get_input_size(self, model_name):\n",
        "        return self.models_[model_name][\"input_shape\"][:2]\n",
        "\n",
        "\n",
        "    def get_model(self, class_names, model_name=\"DenseNet121\", use_base_weights=None,\n",
        "                  weights_path=\"/content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\", input_shape=None):\n",
        "\n",
        "        if use_base_weights is True:\n",
        "            base_weights = \"imagenet\"\n",
        "        else:\n",
        "            base_weights = None\n",
        "\n",
        "        base_model_class = getattr(\n",
        "            importlib.import_module(\n",
        "                f\"keras.applications.{self.models_[model_name]['module_name']}\"\n",
        "            ),\n",
        "            model_name)\n",
        "\n",
        "        if input_shape is None:\n",
        "            input_shape = self.models_[model_name][\"input_shape\"]\n",
        "\n",
        "        img_input = Input(shape=input_shape)\n",
        "\n",
        "        base_model = base_model_class(\n",
        "            include_top=False,\n",
        "            input_tensor=img_input,\n",
        "            input_shape=input_shape,\n",
        "            weights=base_weights,\n",
        "            pooling=\"avg\")\n",
        "        x = base_model.output\n",
        "        predictions = Dense(len(class_names), activation=\"softmax\", name=\"predictions\")(x)\n",
        "        model = Model(inputs=img_input, outputs=predictions)\n",
        "\n",
        "        if weights_path == \"\":\n",
        "            weights_path = None\n",
        "\n",
        "        if weights_path is not None:\n",
        "            print(f\"load model weights_path: {weights_path}\")\n",
        "            model.load_weights(weights_path)\n",
        "        return model,predictions,img_input,x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OQaU9UvJza7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fine_tuning,dense_layer,dropout1,dropout2,learning_rate\n",
        "lb=[1,0,0,0]\n",
        "ub=[120,3,0.65,0.65]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c21jOAu_H30r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(x):\n",
        "  \n",
        "  print(x[0],x[1],x[2],x[3])\n",
        "  \n",
        "  model=ModelFactory()\n",
        "  montelo,a,b,c=model.get_model(['0','1','2','3','4','5','6','7','8','9','10','11','12','13'])\n",
        "  \n",
        "  montelo._layers.pop()\n",
        "  \n",
        "  for layer in montelo.layers[:(-1)*int(round(x[0]))]:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(montelo)\n",
        "  \n",
        "  if (int(round(x[1]))==3):\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.5))\n",
        "    model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(x[2]))\n",
        "    model.add(keras.layers.Dense(32, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(x[3]))\n",
        "  elif (int(round(x[1]))==2):\n",
        "    model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(x[2]))\n",
        "    model.add(keras.layers.Dense(32, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(x[3]))\n",
        "  elif (int(round(x[1]))==1):\n",
        "    model.add(keras.layers.Dense(32, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(x[2]))\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  for layer in model.layers:\n",
        "    print(layer, layer.trainable)\n",
        "  model.add(keras.layers.Dense(3,activation=\"softmax\"))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7s3lpAAJXvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EarlyStopper = EarlyStopping(patience=7, monitor='val_loss', mode='min')\n",
        "count = 0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6OGoQ7hJb_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apple(x):\n",
        "  model = create_model(x)\n",
        "  model.fit(x_train, y_train, epochs=45, batch_size=1000, verbose=1,validation_data=(x_test, y_test),callbacks=[EarlyStopper])\n",
        "  loss, acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "  if acc>0.88:\n",
        "    print(x)\n",
        "    pred_chest_xnet=model.predict_classes(test64)\n",
        "    print(classification_report(labels, pred_chest_xnet,target_names=target_names))\n",
        "  return loss"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LID8JEpzJm-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "120e4c32-ae2f-455a-aeb8-6ce2c4a89153"
      },
      "source": [
        "xopt, fopt = pso(apple, lb, ub, swarmsize=10, omega=0.5, phip=0.5, phig=1.0, maxiter=30, minstep=1)\n",
        "print (\"Best position\"+str(xopt))\n",
        "print (\"Loss:\" + str(fopt))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71.20351594350059 2.772540227219851 0.5806898623685807 0.5527694597734293\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f1a668b2940> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f1a667e3208> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f1a66457860> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f1a667e33c8> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f1a6646bf28> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f1a66475400> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f1a66406630> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 6s 333ms/step - loss: 1.0950 - accuracy: 0.3749 - val_loss: 1.0561 - val_accuracy: 0.4640\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 1.0677 - accuracy: 0.4299 - val_loss: 1.0538 - val_accuracy: 0.4640\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 182ms/step - loss: 1.0305 - accuracy: 0.4563 - val_loss: 1.0534 - val_accuracy: 0.4640\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 183ms/step - loss: 0.9487 - accuracy: 0.5415 - val_loss: 1.0276 - val_accuracy: 0.4817\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 182ms/step - loss: 0.8460 - accuracy: 0.6174 - val_loss: 0.9384 - val_accuracy: 0.5513\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 182ms/step - loss: 0.7570 - accuracy: 0.6666 - val_loss: 1.1060 - val_accuracy: 0.4351\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 182ms/step - loss: 0.7009 - accuracy: 0.7001 - val_loss: 1.3378 - val_accuracy: 0.3445\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 0.6383 - accuracy: 0.7525 - val_loss: 1.4265 - val_accuracy: 0.3428\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 182ms/step - loss: 0.5792 - accuracy: 0.7927 - val_loss: 1.6729 - val_accuracy: 0.3339\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 183ms/step - loss: 0.5336 - accuracy: 0.8201 - val_loss: 1.9191 - val_accuracy: 0.3295\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 182ms/step - loss: 0.4879 - accuracy: 0.8437 - val_loss: 2.0043 - val_accuracy: 0.3433\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 0.4513 - accuracy: 0.8570 - val_loss: 2.1042 - val_accuracy: 0.3500\n",
            "127/127 [==============================] - 2s 18ms/step - loss: 2.1042 - accuracy: 0.3500\n",
            "109.73410571179822 2.0837224077928327 0.6492397601127883 0.10163610581869877\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f18446f4940> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f184461cf98> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f18441bedd8> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f1844644128> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f18441db8d0> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 5s 283ms/step - loss: 1.1107 - accuracy: 0.3322 - val_loss: 1.0756 - val_accuracy: 0.4640\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 1.0662 - accuracy: 0.4653 - val_loss: 1.0575 - val_accuracy: 0.4640\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 1.0065 - accuracy: 0.4960 - val_loss: 1.0656 - val_accuracy: 0.3364\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 189ms/step - loss: 0.8933 - accuracy: 0.5950 - val_loss: 1.0956 - val_accuracy: 0.3435\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.7575 - accuracy: 0.7220 - val_loss: 1.0398 - val_accuracy: 0.4427\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.6269 - accuracy: 0.8036 - val_loss: 0.8172 - val_accuracy: 0.6441\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 189ms/step - loss: 0.5366 - accuracy: 0.8332 - val_loss: 0.7452 - val_accuracy: 0.6987\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 189ms/step - loss: 0.4607 - accuracy: 0.8613 - val_loss: 0.7383 - val_accuracy: 0.7095\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.4048 - accuracy: 0.8787 - val_loss: 0.7948 - val_accuracy: 0.6890\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.3694 - accuracy: 0.8918 - val_loss: 0.7816 - val_accuracy: 0.6942\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.3366 - accuracy: 0.9033 - val_loss: 0.7218 - val_accuracy: 0.7108\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 188ms/step - loss: 0.3144 - accuracy: 0.9083 - val_loss: 0.6770 - val_accuracy: 0.7357\n",
            "Epoch 13/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.2895 - accuracy: 0.9176 - val_loss: 0.6887 - val_accuracy: 0.7379\n",
            "Epoch 14/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.2770 - accuracy: 0.9244 - val_loss: 0.7029 - val_accuracy: 0.7409\n",
            "Epoch 15/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.2507 - accuracy: 0.9330 - val_loss: 0.7058 - val_accuracy: 0.7426\n",
            "Epoch 16/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.2371 - accuracy: 0.9377 - val_loss: 0.6376 - val_accuracy: 0.7695\n",
            "Epoch 17/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.2226 - accuracy: 0.9410 - val_loss: 0.5900 - val_accuracy: 0.7860\n",
            "Epoch 18/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.2244 - accuracy: 0.9413 - val_loss: 0.5804 - val_accuracy: 0.8006\n",
            "Epoch 19/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.2085 - accuracy: 0.9464 - val_loss: 0.5489 - val_accuracy: 0.8090\n",
            "Epoch 20/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.1875 - accuracy: 0.9525 - val_loss: 0.5870 - val_accuracy: 0.8045\n",
            "Epoch 21/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.1812 - accuracy: 0.9558 - val_loss: 0.6125 - val_accuracy: 0.8013\n",
            "Epoch 22/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.1647 - accuracy: 0.9597 - val_loss: 0.5491 - val_accuracy: 0.8265\n",
            "Epoch 23/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.1622 - accuracy: 0.9619 - val_loss: 0.5443 - val_accuracy: 0.8344\n",
            "Epoch 24/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.1562 - accuracy: 0.9626 - val_loss: 0.5645 - val_accuracy: 0.8253\n",
            "Epoch 25/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.1639 - accuracy: 0.9592 - val_loss: 0.5128 - val_accuracy: 0.8450\n",
            "Epoch 26/45\n",
            "17/17 [==============================] - 3s 189ms/step - loss: 0.1548 - accuracy: 0.9629 - val_loss: 0.5206 - val_accuracy: 0.8430\n",
            "Epoch 27/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.1412 - accuracy: 0.9663 - val_loss: 0.4611 - val_accuracy: 0.8633\n",
            "Epoch 28/45\n",
            "17/17 [==============================] - 3s 189ms/step - loss: 0.1455 - accuracy: 0.9664 - val_loss: 0.5038 - val_accuracy: 0.8539\n",
            "Epoch 29/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.1271 - accuracy: 0.9718 - val_loss: 0.4957 - val_accuracy: 0.8561\n",
            "Epoch 30/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.1184 - accuracy: 0.9746 - val_loss: 0.4321 - val_accuracy: 0.8736\n",
            "Epoch 31/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.1067 - accuracy: 0.9772 - val_loss: 0.4729 - val_accuracy: 0.8697\n",
            "Epoch 32/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.1052 - accuracy: 0.9779 - val_loss: 0.4730 - val_accuracy: 0.8707\n",
            "Epoch 33/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.1024 - accuracy: 0.9770 - val_loss: 0.4809 - val_accuracy: 0.8690\n",
            "Epoch 34/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.0912 - accuracy: 0.9817 - val_loss: 0.4802 - val_accuracy: 0.8776\n",
            "Epoch 35/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.0921 - accuracy: 0.9806 - val_loss: 0.5078 - val_accuracy: 0.8697\n",
            "Epoch 36/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.0848 - accuracy: 0.9820 - val_loss: 0.5242 - val_accuracy: 0.8746\n",
            "Epoch 37/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.0893 - accuracy: 0.9803 - val_loss: 0.4901 - val_accuracy: 0.8801\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.4901 - accuracy: 0.8801\n",
            "[1.09734106e+02 2.08372241e+00 6.49239760e-01 1.01636106e-01]\n",
            "WARNING:tensorflow:From <ipython-input-9-e6955d50a896>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     covid19       0.51      0.65      0.57        80\n",
            "      normal       0.87      0.90      0.88       905\n",
            "   pneumonia       0.87      0.82      0.84       800\n",
            "\n",
            "    accuracy                           0.85      1785\n",
            "   macro avg       0.75      0.79      0.77      1785\n",
            "weighted avg       0.86      0.85      0.85      1785\n",
            "\n",
            "57.532637415017604 0.10671461150437567 0.1651631051789349 0.05988029486825886\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f18435cab38> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 5s 268ms/step - loss: 1.0827 - accuracy: 0.3414 - val_loss: 1.0859 - val_accuracy: 0.3218\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 1.0600 - accuracy: 0.3965 - val_loss: 1.0784 - val_accuracy: 0.3218\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 1.0310 - accuracy: 0.4953 - val_loss: 1.0716 - val_accuracy: 0.3265\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.9920 - accuracy: 0.6145 - val_loss: 1.0606 - val_accuracy: 0.4284\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.9532 - accuracy: 0.6621 - val_loss: 1.0439 - val_accuracy: 0.5407\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 0.9250 - accuracy: 0.6731 - val_loss: 1.0246 - val_accuracy: 0.5901\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.8917 - accuracy: 0.6935 - val_loss: 1.0128 - val_accuracy: 0.5982\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.8503 - accuracy: 0.7197 - val_loss: 1.0084 - val_accuracy: 0.5859\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.7951 - accuracy: 0.7896 - val_loss: 1.0071 - val_accuracy: 0.5661\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.7483 - accuracy: 0.8335 - val_loss: 1.0228 - val_accuracy: 0.4923\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.7159 - accuracy: 0.8558 - val_loss: 1.0232 - val_accuracy: 0.4768\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.6868 - accuracy: 0.8733 - val_loss: 1.0262 - val_accuracy: 0.4585\n",
            "Epoch 13/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.6593 - accuracy: 0.8889 - val_loss: 1.0085 - val_accuracy: 0.5002\n",
            "Epoch 14/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.6351 - accuracy: 0.8968 - val_loss: 1.0090 - val_accuracy: 0.4938\n",
            "Epoch 15/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.6165 - accuracy: 0.9017 - val_loss: 1.0005 - val_accuracy: 0.5035\n",
            "Epoch 16/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.5984 - accuracy: 0.9055 - val_loss: 0.9866 - val_accuracy: 0.5207\n",
            "Epoch 17/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.5811 - accuracy: 0.9085 - val_loss: 0.9711 - val_accuracy: 0.5447\n",
            "Epoch 18/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.5621 - accuracy: 0.9161 - val_loss: 0.9692 - val_accuracy: 0.5308\n",
            "Epoch 19/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.5487 - accuracy: 0.9161 - val_loss: 0.9543 - val_accuracy: 0.5548\n",
            "Epoch 20/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.5311 - accuracy: 0.9230 - val_loss: 0.9344 - val_accuracy: 0.5531\n",
            "Epoch 21/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.5156 - accuracy: 0.9271 - val_loss: 0.9158 - val_accuracy: 0.5617\n",
            "Epoch 22/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.5056 - accuracy: 0.9269 - val_loss: 0.9049 - val_accuracy: 0.5550\n",
            "Epoch 23/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.4889 - accuracy: 0.9324 - val_loss: 0.8790 - val_accuracy: 0.5856\n",
            "Epoch 24/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.4737 - accuracy: 0.9368 - val_loss: 0.8881 - val_accuracy: 0.5590\n",
            "Epoch 25/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.4614 - accuracy: 0.9401 - val_loss: 0.8891 - val_accuracy: 0.5444\n",
            "Epoch 26/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.4521 - accuracy: 0.9398 - val_loss: 0.8656 - val_accuracy: 0.5760\n",
            "Epoch 27/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.4368 - accuracy: 0.9445 - val_loss: 0.8588 - val_accuracy: 0.5785\n",
            "Epoch 28/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.4271 - accuracy: 0.9466 - val_loss: 0.8231 - val_accuracy: 0.6172\n",
            "Epoch 29/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.4157 - accuracy: 0.9473 - val_loss: 0.7753 - val_accuracy: 0.6705\n",
            "Epoch 30/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.4026 - accuracy: 0.9511 - val_loss: 0.7766 - val_accuracy: 0.6557\n",
            "Epoch 31/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.3934 - accuracy: 0.9520 - val_loss: 0.7062 - val_accuracy: 0.7423\n",
            "Epoch 32/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.3841 - accuracy: 0.9538 - val_loss: 0.7139 - val_accuracy: 0.7194\n",
            "Epoch 33/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.3750 - accuracy: 0.9526 - val_loss: 0.6832 - val_accuracy: 0.7483\n",
            "Epoch 34/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.3607 - accuracy: 0.9571 - val_loss: 0.6260 - val_accuracy: 0.7900\n",
            "Epoch 35/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.3502 - accuracy: 0.9586 - val_loss: 0.6184 - val_accuracy: 0.7890\n",
            "Epoch 36/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.3382 - accuracy: 0.9616 - val_loss: 0.6216 - val_accuracy: 0.7818\n",
            "Epoch 37/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.3314 - accuracy: 0.9617 - val_loss: 0.5754 - val_accuracy: 0.8147\n",
            "Epoch 38/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 0.3267 - accuracy: 0.9593 - val_loss: 0.5312 - val_accuracy: 0.8398\n",
            "Epoch 39/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.3196 - accuracy: 0.9603 - val_loss: 0.5267 - val_accuracy: 0.8386\n",
            "Epoch 40/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.3115 - accuracy: 0.9617 - val_loss: 0.5175 - val_accuracy: 0.8421\n",
            "Epoch 41/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.3059 - accuracy: 0.9619 - val_loss: 0.4740 - val_accuracy: 0.8638\n",
            "Epoch 42/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.2945 - accuracy: 0.9653 - val_loss: 0.4963 - val_accuracy: 0.8490\n",
            "Epoch 43/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.2956 - accuracy: 0.9618 - val_loss: 0.4753 - val_accuracy: 0.8566\n",
            "Epoch 44/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.2877 - accuracy: 0.9645 - val_loss: 0.4400 - val_accuracy: 0.8741\n",
            "Epoch 45/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 0.2757 - accuracy: 0.9673 - val_loss: 0.4506 - val_accuracy: 0.8640\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.4506 - accuracy: 0.8640\n",
            "58.87507013977189 0.8566552709663133 0.11997656087342651 0.6234220525712696\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f1a6099d780> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f1a60694e80> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f1a6325a080> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 5s 299ms/step - loss: 1.1388 - accuracy: 0.3086 - val_loss: 1.1210 - val_accuracy: 0.3218\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 1.0963 - accuracy: 0.3539 - val_loss: 1.0927 - val_accuracy: 0.3218\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 1.0527 - accuracy: 0.4774 - val_loss: 1.0771 - val_accuracy: 0.3253\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.9857 - accuracy: 0.5985 - val_loss: 1.0557 - val_accuracy: 0.4733\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.9109 - accuracy: 0.6516 - val_loss: 1.0354 - val_accuracy: 0.5015\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.8432 - accuracy: 0.6877 - val_loss: 1.0190 - val_accuracy: 0.5141\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.7857 - accuracy: 0.6989 - val_loss: 0.9989 - val_accuracy: 0.5405\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.7369 - accuracy: 0.7044 - val_loss: 0.9772 - val_accuracy: 0.5644\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.6922 - accuracy: 0.7106 - val_loss: 0.9480 - val_accuracy: 0.5970\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.6570 - accuracy: 0.7126 - val_loss: 0.9422 - val_accuracy: 0.5866\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 0.6284 - accuracy: 0.7181 - val_loss: 0.9388 - val_accuracy: 0.5812\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.6060 - accuracy: 0.7221 - val_loss: 0.9362 - val_accuracy: 0.5763\n",
            "Epoch 13/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.5883 - accuracy: 0.7235 - val_loss: 0.9133 - val_accuracy: 0.5859\n",
            "Epoch 14/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.5743 - accuracy: 0.7243 - val_loss: 0.9255 - val_accuracy: 0.5689\n",
            "Epoch 15/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 0.5557 - accuracy: 0.7291 - val_loss: 0.9266 - val_accuracy: 0.5649\n",
            "Epoch 16/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.5422 - accuracy: 0.7317 - val_loss: 0.9164 - val_accuracy: 0.5706\n",
            "Epoch 17/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.5323 - accuracy: 0.7377 - val_loss: 0.9390 - val_accuracy: 0.5402\n",
            "Epoch 18/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 0.5132 - accuracy: 0.7453 - val_loss: 0.9234 - val_accuracy: 0.5518\n",
            "Epoch 19/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.4970 - accuracy: 0.7515 - val_loss: 0.9266 - val_accuracy: 0.5521\n",
            "Epoch 20/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.4798 - accuracy: 0.7565 - val_loss: 0.8915 - val_accuracy: 0.5706\n",
            "Epoch 21/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.4623 - accuracy: 0.7789 - val_loss: 0.8824 - val_accuracy: 0.5980\n",
            "Epoch 22/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.4378 - accuracy: 0.8337 - val_loss: 0.8679 - val_accuracy: 0.5921\n",
            "Epoch 23/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.4075 - accuracy: 0.8731 - val_loss: 0.8290 - val_accuracy: 0.6096\n",
            "Epoch 24/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.3772 - accuracy: 0.8951 - val_loss: 0.8089 - val_accuracy: 0.6283\n",
            "Epoch 25/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.3474 - accuracy: 0.9072 - val_loss: 0.7832 - val_accuracy: 0.6429\n",
            "Epoch 26/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.3139 - accuracy: 0.9174 - val_loss: 0.8084 - val_accuracy: 0.6515\n",
            "Epoch 27/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 0.2846 - accuracy: 0.9210 - val_loss: 0.7480 - val_accuracy: 0.6883\n",
            "Epoch 28/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.2601 - accuracy: 0.9266 - val_loss: 0.7195 - val_accuracy: 0.7048\n",
            "Epoch 29/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.2428 - accuracy: 0.9294 - val_loss: 0.7653 - val_accuracy: 0.6950\n",
            "Epoch 30/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.2286 - accuracy: 0.9331 - val_loss: 0.6798 - val_accuracy: 0.7359\n",
            "Epoch 31/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.2014 - accuracy: 0.9427 - val_loss: 0.5854 - val_accuracy: 0.7705\n",
            "Epoch 32/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.1804 - accuracy: 0.9504 - val_loss: 0.5794 - val_accuracy: 0.7818\n",
            "Epoch 33/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.1638 - accuracy: 0.9566 - val_loss: 0.6877 - val_accuracy: 0.7347\n",
            "Epoch 34/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.1543 - accuracy: 0.9602 - val_loss: 0.6279 - val_accuracy: 0.7609\n",
            "Epoch 35/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.1396 - accuracy: 0.9631 - val_loss: 0.6033 - val_accuracy: 0.7596\n",
            "Epoch 36/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.1283 - accuracy: 0.9669 - val_loss: 0.5782 - val_accuracy: 0.7843\n",
            "Epoch 37/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 0.1282 - accuracy: 0.9655 - val_loss: 0.5329 - val_accuracy: 0.8090\n",
            "Epoch 38/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.1218 - accuracy: 0.9669 - val_loss: 0.5016 - val_accuracy: 0.8117\n",
            "Epoch 39/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.1084 - accuracy: 0.9729 - val_loss: 0.5291 - val_accuracy: 0.7947\n",
            "Epoch 40/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.0969 - accuracy: 0.9765 - val_loss: 0.5809 - val_accuracy: 0.7843\n",
            "Epoch 41/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.0896 - accuracy: 0.9790 - val_loss: 0.5453 - val_accuracy: 0.8036\n",
            "Epoch 42/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.0813 - accuracy: 0.9824 - val_loss: 0.5525 - val_accuracy: 0.8073\n",
            "Epoch 43/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.0790 - accuracy: 0.9809 - val_loss: 0.4955 - val_accuracy: 0.8309\n",
            "Epoch 44/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.0780 - accuracy: 0.9808 - val_loss: 0.5277 - val_accuracy: 0.8260\n",
            "Epoch 45/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.0813 - accuracy: 0.9780 - val_loss: 0.5021 - val_accuracy: 0.8305\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.5021 - accuracy: 0.8305\n",
            "51.26944463501532 2.3336243758549875 0.3188286371112502 0.2601003435276156\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f1842ab1ac8> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f18429a75f8> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f18424b73c8> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f18429a76d8> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f184244be48> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 5s 272ms/step - loss: 1.0827 - accuracy: 0.4017 - val_loss: 1.0559 - val_accuracy: 0.4640\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 1.0561 - accuracy: 0.4532 - val_loss: 1.0516 - val_accuracy: 0.4640\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 1.0264 - accuracy: 0.4646 - val_loss: 1.0546 - val_accuracy: 0.4640\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 0.9477 - accuracy: 0.5574 - val_loss: 1.1029 - val_accuracy: 0.4640\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 0.8347 - accuracy: 0.6281 - val_loss: 1.1290 - val_accuracy: 0.4706\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.7213 - accuracy: 0.6776 - val_loss: 1.0351 - val_accuracy: 0.4948\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.6418 - accuracy: 0.7319 - val_loss: 1.0038 - val_accuracy: 0.5042\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 0.5764 - accuracy: 0.7863 - val_loss: 1.0536 - val_accuracy: 0.4857\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 0.5148 - accuracy: 0.8198 - val_loss: 1.1660 - val_accuracy: 0.4353\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 176ms/step - loss: 0.4643 - accuracy: 0.8432 - val_loss: 1.2459 - val_accuracy: 0.4307\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 176ms/step - loss: 0.4287 - accuracy: 0.8538 - val_loss: 1.4201 - val_accuracy: 0.3934\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 0.3936 - accuracy: 0.8684 - val_loss: 1.4929 - val_accuracy: 0.3919\n",
            "Epoch 13/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.3673 - accuracy: 0.8757 - val_loss: 1.5549 - val_accuracy: 0.3897\n",
            "Epoch 14/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 0.3516 - accuracy: 0.8833 - val_loss: 1.6020 - val_accuracy: 0.3914\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 1.6020 - accuracy: 0.3914\n",
            "68.15494925535303 2.968003575040848 0.16104065527171338 0.5449923208414065\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f183f688780> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f183f57f2e8> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f183f6084e0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f183f57f470> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f183f1f9e48> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f183f1ff390> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f183f20e0f0> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 5s 308ms/step - loss: 1.0793 - accuracy: 0.4268 - val_loss: 1.0563 - val_accuracy: 0.4640\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 182ms/step - loss: 1.0565 - accuracy: 0.4532 - val_loss: 1.0520 - val_accuracy: 0.4640\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 182ms/step - loss: 1.0177 - accuracy: 0.4666 - val_loss: 1.0706 - val_accuracy: 0.4640\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 182ms/step - loss: 0.9083 - accuracy: 0.5721 - val_loss: 1.1612 - val_accuracy: 0.4669\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 182ms/step - loss: 0.7851 - accuracy: 0.6509 - val_loss: 1.0234 - val_accuracy: 0.5084\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 182ms/step - loss: 0.7032 - accuracy: 0.6958 - val_loss: 0.9512 - val_accuracy: 0.5405\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 183ms/step - loss: 0.6298 - accuracy: 0.7520 - val_loss: 1.0336 - val_accuracy: 0.4815\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 184ms/step - loss: 0.5510 - accuracy: 0.8036 - val_loss: 1.1019 - val_accuracy: 0.4709\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 182ms/step - loss: 0.4878 - accuracy: 0.8382 - val_loss: 1.2155 - val_accuracy: 0.4408\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 0.4605 - accuracy: 0.8542 - val_loss: 1.2582 - val_accuracy: 0.4467\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 0.4345 - accuracy: 0.8638 - val_loss: 1.3536 - val_accuracy: 0.4215\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.4109 - accuracy: 0.8708 - val_loss: 1.5413 - val_accuracy: 0.3946\n",
            "Epoch 13/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 0.3892 - accuracy: 0.8837 - val_loss: 1.5911 - val_accuracy: 0.4119\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 1.5911 - accuracy: 0.4119\n",
            "12.059546284135825 1.2597111049659406 0.29449151836646253 0.5663181608920428\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f1840c64080> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f1840bdfb38> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f184094a1d0> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 4s 258ms/step - loss: 1.0746 - accuracy: 0.4129 - val_loss: 1.0573 - val_accuracy: 0.4640\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 168ms/step - loss: 1.0585 - accuracy: 0.4496 - val_loss: 1.0518 - val_accuracy: 0.4640\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 168ms/step - loss: 1.0439 - accuracy: 0.4607 - val_loss: 1.0511 - val_accuracy: 0.4640\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 168ms/step - loss: 1.0131 - accuracy: 0.4906 - val_loss: 1.0514 - val_accuracy: 0.4637\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 169ms/step - loss: 0.9693 - accuracy: 0.5357 - val_loss: 1.0473 - val_accuracy: 0.4650\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 168ms/step - loss: 0.9206 - accuracy: 0.5796 - val_loss: 1.0305 - val_accuracy: 0.4689\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 168ms/step - loss: 0.8592 - accuracy: 0.6311 - val_loss: 1.0132 - val_accuracy: 0.4869\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 169ms/step - loss: 0.7930 - accuracy: 0.6825 - val_loss: 1.0373 - val_accuracy: 0.4672\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 168ms/step - loss: 0.7384 - accuracy: 0.7161 - val_loss: 1.0879 - val_accuracy: 0.4252\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 169ms/step - loss: 0.6893 - accuracy: 0.7414 - val_loss: 1.1218 - val_accuracy: 0.4245\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 169ms/step - loss: 0.6517 - accuracy: 0.7637 - val_loss: 1.1364 - val_accuracy: 0.4311\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 168ms/step - loss: 0.6264 - accuracy: 0.7686 - val_loss: 1.1808 - val_accuracy: 0.4183\n",
            "Epoch 13/45\n",
            "17/17 [==============================] - 3s 169ms/step - loss: 0.5980 - accuracy: 0.7856 - val_loss: 1.1733 - val_accuracy: 0.4331\n",
            "Epoch 14/45\n",
            "17/17 [==============================] - 3s 169ms/step - loss: 0.5799 - accuracy: 0.7952 - val_loss: 1.1542 - val_accuracy: 0.4511\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 1.1542 - accuracy: 0.4511\n",
            "48.21160678649265 2.250703449491736 0.2625390963810511 0.4359954869623294\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f183e778cf8> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f183e7bc3c8> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f183e70d5c0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f183e7bc550> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f183ebddfd0> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 5s 265ms/step - loss: 1.0848 - accuracy: 0.4050 - val_loss: 1.0565 - val_accuracy: 0.4640\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 1.0597 - accuracy: 0.4497 - val_loss: 1.0515 - val_accuracy: 0.4640\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 1.0551 - accuracy: 0.4508 - val_loss: 1.0531 - val_accuracy: 0.4640\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 1.0298 - accuracy: 0.4665 - val_loss: 1.0556 - val_accuracy: 0.4640\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.9402 - accuracy: 0.5629 - val_loss: 1.0814 - val_accuracy: 0.3670\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 0.8086 - accuracy: 0.6637 - val_loss: 1.1539 - val_accuracy: 0.3561\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 176ms/step - loss: 0.7305 - accuracy: 0.6869 - val_loss: 1.2166 - val_accuracy: 0.3564\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.6776 - accuracy: 0.6976 - val_loss: 1.2443 - val_accuracy: 0.3860\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.6483 - accuracy: 0.6987 - val_loss: 1.2175 - val_accuracy: 0.4282\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 1.2175 - accuracy: 0.4282\n",
            "116.89664050306796 1.2274530004730164 0.33635310807134133 0.6195055515801734\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f183a08c390> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f1839f7aeb8> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f1839fce0b8> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 5s 287ms/step - loss: 1.1090 - accuracy: 0.3301 - val_loss: 1.0930 - val_accuracy: 0.3218\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 1.0675 - accuracy: 0.4732 - val_loss: 1.0761 - val_accuracy: 0.4640\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 1.0312 - accuracy: 0.5521 - val_loss: 1.0713 - val_accuracy: 0.3620\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 194ms/step - loss: 0.9732 - accuracy: 0.6127 - val_loss: 1.0277 - val_accuracy: 0.5301\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.8979 - accuracy: 0.6616 - val_loss: 0.9336 - val_accuracy: 0.6604\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.8244 - accuracy: 0.6902 - val_loss: 0.8637 - val_accuracy: 0.6779\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 194ms/step - loss: 0.7642 - accuracy: 0.7048 - val_loss: 0.8043 - val_accuracy: 0.6769\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 194ms/step - loss: 0.7137 - accuracy: 0.7146 - val_loss: 0.7665 - val_accuracy: 0.6774\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.6729 - accuracy: 0.7217 - val_loss: 0.7673 - val_accuracy: 0.6567\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 194ms/step - loss: 0.6391 - accuracy: 0.7272 - val_loss: 0.7336 - val_accuracy: 0.6678\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.6115 - accuracy: 0.7315 - val_loss: 0.7588 - val_accuracy: 0.6567\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.5939 - accuracy: 0.7332 - val_loss: 0.7309 - val_accuracy: 0.6614\n",
            "Epoch 13/45\n",
            "17/17 [==============================] - 3s 194ms/step - loss: 0.5731 - accuracy: 0.7343 - val_loss: 0.6754 - val_accuracy: 0.6809\n",
            "Epoch 14/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.5570 - accuracy: 0.7391 - val_loss: 0.6527 - val_accuracy: 0.6883\n",
            "Epoch 15/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.5438 - accuracy: 0.7430 - val_loss: 0.6502 - val_accuracy: 0.6866\n",
            "Epoch 16/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.5307 - accuracy: 0.7446 - val_loss: 0.6354 - val_accuracy: 0.6920\n",
            "Epoch 17/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.5195 - accuracy: 0.7456 - val_loss: 0.6355 - val_accuracy: 0.6927\n",
            "Epoch 18/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.5123 - accuracy: 0.7465 - val_loss: 0.6098 - val_accuracy: 0.6999\n",
            "Epoch 19/45\n",
            "17/17 [==============================] - 3s 194ms/step - loss: 0.5042 - accuracy: 0.7510 - val_loss: 0.6106 - val_accuracy: 0.6987\n",
            "Epoch 20/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.4912 - accuracy: 0.7577 - val_loss: 0.6027 - val_accuracy: 0.6999\n",
            "Epoch 21/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.4846 - accuracy: 0.7570 - val_loss: 0.6116 - val_accuracy: 0.6987\n",
            "Epoch 22/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.4738 - accuracy: 0.7599 - val_loss: 0.6040 - val_accuracy: 0.6903\n",
            "Epoch 23/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.4557 - accuracy: 0.7663 - val_loss: 0.5775 - val_accuracy: 0.7004\n",
            "Epoch 24/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.4175 - accuracy: 0.8051 - val_loss: 0.5724 - val_accuracy: 0.8152\n",
            "Epoch 25/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.3647 - accuracy: 0.8763 - val_loss: 0.5438 - val_accuracy: 0.8105\n",
            "Epoch 26/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.3139 - accuracy: 0.9155 - val_loss: 0.5429 - val_accuracy: 0.7838\n",
            "Epoch 27/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.2650 - accuracy: 0.9349 - val_loss: 0.5056 - val_accuracy: 0.8092\n",
            "Epoch 28/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.2313 - accuracy: 0.9466 - val_loss: 0.5383 - val_accuracy: 0.7828\n",
            "Epoch 29/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.2064 - accuracy: 0.9526 - val_loss: 0.4702 - val_accuracy: 0.8268\n",
            "Epoch 30/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.1868 - accuracy: 0.9579 - val_loss: 0.4784 - val_accuracy: 0.8277\n",
            "Epoch 31/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.1661 - accuracy: 0.9638 - val_loss: 0.5529 - val_accuracy: 0.7875\n",
            "Epoch 32/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.1572 - accuracy: 0.9663 - val_loss: 0.5384 - val_accuracy: 0.8065\n",
            "Epoch 33/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.1435 - accuracy: 0.9708 - val_loss: 0.4700 - val_accuracy: 0.8418\n",
            "Epoch 34/45\n",
            "17/17 [==============================] - 3s 194ms/step - loss: 0.1292 - accuracy: 0.9737 - val_loss: 0.4307 - val_accuracy: 0.8608\n",
            "Epoch 35/45\n",
            "17/17 [==============================] - 3s 194ms/step - loss: 0.1262 - accuracy: 0.9744 - val_loss: 0.4275 - val_accuracy: 0.8643\n",
            "Epoch 36/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.1167 - accuracy: 0.9775 - val_loss: 0.4886 - val_accuracy: 0.8490\n",
            "Epoch 37/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.1132 - accuracy: 0.9783 - val_loss: 0.4587 - val_accuracy: 0.8657\n",
            "Epoch 38/45\n",
            "17/17 [==============================] - 3s 194ms/step - loss: 0.1037 - accuracy: 0.9804 - val_loss: 0.4331 - val_accuracy: 0.8692\n",
            "Epoch 39/45\n",
            "17/17 [==============================] - 3s 194ms/step - loss: 0.0975 - accuracy: 0.9816 - val_loss: 0.4399 - val_accuracy: 0.8714\n",
            "Epoch 40/45\n",
            "17/17 [==============================] - 3s 197ms/step - loss: 0.0903 - accuracy: 0.9837 - val_loss: 0.4602 - val_accuracy: 0.8704\n",
            "Epoch 41/45\n",
            "17/17 [==============================] - 3s 194ms/step - loss: 0.0902 - accuracy: 0.9842 - val_loss: 0.4218 - val_accuracy: 0.8828\n",
            "Epoch 42/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.0838 - accuracy: 0.9857 - val_loss: 0.4177 - val_accuracy: 0.8885\n",
            "Epoch 43/45\n",
            "17/17 [==============================] - 3s 195ms/step - loss: 0.0865 - accuracy: 0.9837 - val_loss: 0.4230 - val_accuracy: 0.8875\n",
            "Epoch 44/45\n",
            "17/17 [==============================] - 3s 196ms/step - loss: 0.0978 - accuracy: 0.9797 - val_loss: 0.4817 - val_accuracy: 0.8788\n",
            "Epoch 45/45\n",
            "17/17 [==============================] - 3s 193ms/step - loss: 0.0850 - accuracy: 0.9840 - val_loss: 0.4249 - val_accuracy: 0.8929\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.4249 - accuracy: 0.8929\n",
            "[116.8966405    1.227453     0.33635311   0.61950555]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     covid19       0.59      0.59      0.59        80\n",
            "      normal       0.89      0.89      0.89       905\n",
            "   pneumonia       0.86      0.86      0.86       800\n",
            "\n",
            "    accuracy                           0.86      1785\n",
            "   macro avg       0.78      0.78      0.78      1785\n",
            "weighted avg       0.86      0.86      0.86      1785\n",
            "\n",
            "6.971238835722439 2.847433516825318 0.18418250924549734 0.435694788062842\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f183869da90> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f1837d935c0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f1837b6ab70> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f1837d936a0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f1837b04668> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f1837b04b38> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f1837b12898> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 4s 262ms/step - loss: 1.0744 - accuracy: 0.4323 - val_loss: 1.0528 - val_accuracy: 0.4640\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 167ms/step - loss: 1.0625 - accuracy: 0.4478 - val_loss: 1.0550 - val_accuracy: 0.4640\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 1.0582 - accuracy: 0.4552 - val_loss: 1.0535 - val_accuracy: 0.4640\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 1.0554 - accuracy: 0.4563 - val_loss: 1.0514 - val_accuracy: 0.4640\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 167ms/step - loss: 1.0479 - accuracy: 0.4577 - val_loss: 1.0468 - val_accuracy: 0.4640\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 1.0332 - accuracy: 0.4592 - val_loss: 1.0375 - val_accuracy: 0.4650\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 1.0152 - accuracy: 0.4773 - val_loss: 1.0362 - val_accuracy: 0.4568\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 0.9933 - accuracy: 0.4973 - val_loss: 1.0561 - val_accuracy: 0.4087\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 165ms/step - loss: 0.9697 - accuracy: 0.5181 - val_loss: 1.0597 - val_accuracy: 0.4136\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 0.9460 - accuracy: 0.5466 - val_loss: 1.0684 - val_accuracy: 0.4181\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 0.9222 - accuracy: 0.5658 - val_loss: 1.0685 - val_accuracy: 0.4188\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 0.9031 - accuracy: 0.5787 - val_loss: 1.0793 - val_accuracy: 0.4250\n",
            "Epoch 13/45\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 0.8879 - accuracy: 0.5818 - val_loss: 1.0731 - val_accuracy: 0.4191\n",
            "Epoch 14/45\n",
            "17/17 [==============================] - 3s 167ms/step - loss: 0.8733 - accuracy: 0.5882 - val_loss: 1.0648 - val_accuracy: 0.4326\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 1.0648 - accuracy: 0.4326\n",
            "120.0 3.0 0.5183938443660255 0.65\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f183ffe1908> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f183d3abc88> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f183da85f98> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f183d3ab3c8> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f183daa5a20> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f183daa5ef0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f183da7cc88> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 5s 294ms/step - loss: 1.0976 - accuracy: 0.3802 - val_loss: 1.0726 - val_accuracy: 0.4640\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 200ms/step - loss: 1.0523 - accuracy: 0.4444 - val_loss: 1.0677 - val_accuracy: 0.4640\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 199ms/step - loss: 0.9566 - accuracy: 0.4918 - val_loss: 1.0841 - val_accuracy: 0.3349\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 199ms/step - loss: 0.8551 - accuracy: 0.6134 - val_loss: 1.0124 - val_accuracy: 0.4543\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 199ms/step - loss: 0.7729 - accuracy: 0.6705 - val_loss: 0.8097 - val_accuracy: 0.6194\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 198ms/step - loss: 0.7259 - accuracy: 0.6914 - val_loss: 0.7049 - val_accuracy: 0.6767\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 198ms/step - loss: 0.6662 - accuracy: 0.7258 - val_loss: 0.6705 - val_accuracy: 0.6898\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 197ms/step - loss: 0.6014 - accuracy: 0.7862 - val_loss: 0.6187 - val_accuracy: 0.7567\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 198ms/step - loss: 0.5148 - accuracy: 0.8364 - val_loss: 0.5402 - val_accuracy: 0.7971\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 199ms/step - loss: 0.4423 - accuracy: 0.8659 - val_loss: 0.4717 - val_accuracy: 0.8233\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 199ms/step - loss: 0.3828 - accuracy: 0.8876 - val_loss: 0.4041 - val_accuracy: 0.8583\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 200ms/step - loss: 0.3370 - accuracy: 0.9061 - val_loss: 0.3684 - val_accuracy: 0.8665\n",
            "Epoch 13/45\n",
            "17/17 [==============================] - 3s 199ms/step - loss: 0.3043 - accuracy: 0.9178 - val_loss: 0.3770 - val_accuracy: 0.8670\n",
            "Epoch 14/45\n",
            "17/17 [==============================] - 3s 199ms/step - loss: 0.2751 - accuracy: 0.9250 - val_loss: 0.3805 - val_accuracy: 0.8687\n",
            "Epoch 15/45\n",
            "17/17 [==============================] - 3s 198ms/step - loss: 0.2560 - accuracy: 0.9328 - val_loss: 0.3763 - val_accuracy: 0.8788\n",
            "Epoch 16/45\n",
            "17/17 [==============================] - 3s 199ms/step - loss: 0.2372 - accuracy: 0.9375 - val_loss: 0.3863 - val_accuracy: 0.8736\n",
            "Epoch 17/45\n",
            "17/17 [==============================] - 3s 199ms/step - loss: 0.2159 - accuracy: 0.9469 - val_loss: 0.4361 - val_accuracy: 0.8714\n",
            "Epoch 18/45\n",
            "17/17 [==============================] - 3s 199ms/step - loss: 0.2007 - accuracy: 0.9496 - val_loss: 0.4210 - val_accuracy: 0.8741\n",
            "Epoch 19/45\n",
            "17/17 [==============================] - 3s 199ms/step - loss: 0.1884 - accuracy: 0.9526 - val_loss: 0.4329 - val_accuracy: 0.8719\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.4329 - accuracy: 0.8719\n",
            "60.76496520995042 2.1336647924202814 0.4423797041443449 0.65\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f18361a17b8> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f18360c22e8> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f1835d5a2b0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f18360c23c8> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f183e8957b8> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 5s 270ms/step - loss: 1.1056 - accuracy: 0.3730 - val_loss: 1.0639 - val_accuracy: 0.4640\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 1.0780 - accuracy: 0.4286 - val_loss: 1.0559 - val_accuracy: 0.4640\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 1.0639 - accuracy: 0.4373 - val_loss: 1.0539 - val_accuracy: 0.4640\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 1.0343 - accuracy: 0.4511 - val_loss: 1.0470 - val_accuracy: 0.4640\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.9445 - accuracy: 0.5396 - val_loss: 1.0403 - val_accuracy: 0.4669\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.8181 - accuracy: 0.6272 - val_loss: 0.9948 - val_accuracy: 0.5035\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 181ms/step - loss: 0.7305 - accuracy: 0.6704 - val_loss: 0.9181 - val_accuracy: 0.5294\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.6833 - accuracy: 0.6938 - val_loss: 0.9934 - val_accuracy: 0.4884\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.6527 - accuracy: 0.7117 - val_loss: 1.0434 - val_accuracy: 0.4901\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 0.6215 - accuracy: 0.7389 - val_loss: 1.2142 - val_accuracy: 0.4447\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.5943 - accuracy: 0.7662 - val_loss: 1.2385 - val_accuracy: 0.4346\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.5616 - accuracy: 0.7918 - val_loss: 1.4263 - val_accuracy: 0.3926\n",
            "Epoch 13/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.5229 - accuracy: 0.8142 - val_loss: 1.5407 - val_accuracy: 0.3778\n",
            "Epoch 14/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.5045 - accuracy: 0.8218 - val_loss: 1.5673 - val_accuracy: 0.3845\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 1.5673 - accuracy: 0.3845\n",
            "114.38931033793786 0.3251683961029696 0.0013756824562827508 0.2770337280041165\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f1834525b70> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 5s 290ms/step - loss: 1.0949 - accuracy: 0.3031 - val_loss: 1.1126 - val_accuracy: 0.2142\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 1.0240 - accuracy: 0.5224 - val_loss: 1.1057 - val_accuracy: 0.2145\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 194ms/step - loss: 0.9641 - accuracy: 0.6336 - val_loss: 1.0797 - val_accuracy: 0.4608\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.9231 - accuracy: 0.6640 - val_loss: 1.0142 - val_accuracy: 0.6177\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.8956 - accuracy: 0.6828 - val_loss: 0.9665 - val_accuracy: 0.6276\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.8753 - accuracy: 0.6932 - val_loss: 0.9462 - val_accuracy: 0.6209\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.8581 - accuracy: 0.7023 - val_loss: 0.9296 - val_accuracy: 0.6187\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.8422 - accuracy: 0.7090 - val_loss: 0.9185 - val_accuracy: 0.6160\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.8277 - accuracy: 0.7124 - val_loss: 0.8996 - val_accuracy: 0.6404\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.8147 - accuracy: 0.7172 - val_loss: 0.8844 - val_accuracy: 0.6510\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 193ms/step - loss: 0.8015 - accuracy: 0.7208 - val_loss: 0.8730 - val_accuracy: 0.6535\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 193ms/step - loss: 0.7892 - accuracy: 0.7253 - val_loss: 0.8623 - val_accuracy: 0.6572\n",
            "Epoch 13/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.7786 - accuracy: 0.7267 - val_loss: 0.8549 - val_accuracy: 0.6755\n",
            "Epoch 14/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.7667 - accuracy: 0.7361 - val_loss: 0.8348 - val_accuracy: 0.6974\n",
            "Epoch 15/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.7346 - accuracy: 0.7965 - val_loss: 0.8053 - val_accuracy: 0.7458\n",
            "Epoch 16/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.6957 - accuracy: 0.8514 - val_loss: 0.7912 - val_accuracy: 0.7806\n",
            "Epoch 17/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.6692 - accuracy: 0.8720 - val_loss: 0.7522 - val_accuracy: 0.8018\n",
            "Epoch 18/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.6409 - accuracy: 0.8915 - val_loss: 0.7259 - val_accuracy: 0.8203\n",
            "Epoch 19/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.6126 - accuracy: 0.9071 - val_loss: 0.6990 - val_accuracy: 0.8309\n",
            "Epoch 20/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.5899 - accuracy: 0.9184 - val_loss: 0.6735 - val_accuracy: 0.8391\n",
            "Epoch 21/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.5686 - accuracy: 0.9247 - val_loss: 0.6738 - val_accuracy: 0.8337\n",
            "Epoch 22/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.5487 - accuracy: 0.9317 - val_loss: 0.6587 - val_accuracy: 0.8243\n",
            "Epoch 23/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.5335 - accuracy: 0.9344 - val_loss: 0.6360 - val_accuracy: 0.8425\n",
            "Epoch 24/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.5167 - accuracy: 0.9389 - val_loss: 0.6197 - val_accuracy: 0.8512\n",
            "Epoch 25/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.5051 - accuracy: 0.9379 - val_loss: 0.5972 - val_accuracy: 0.8598\n",
            "Epoch 26/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.4887 - accuracy: 0.9436 - val_loss: 0.5883 - val_accuracy: 0.8593\n",
            "Epoch 27/45\n",
            "17/17 [==============================] - 3s 190ms/step - loss: 0.4749 - accuracy: 0.9464 - val_loss: 0.5791 - val_accuracy: 0.8660\n",
            "Epoch 28/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.4615 - accuracy: 0.9490 - val_loss: 0.5751 - val_accuracy: 0.8561\n",
            "Epoch 29/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.4497 - accuracy: 0.9514 - val_loss: 0.5534 - val_accuracy: 0.8670\n",
            "Epoch 30/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.4380 - accuracy: 0.9530 - val_loss: 0.5552 - val_accuracy: 0.8591\n",
            "Epoch 31/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.4305 - accuracy: 0.9521 - val_loss: 0.5588 - val_accuracy: 0.8519\n",
            "Epoch 32/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.4195 - accuracy: 0.9550 - val_loss: 0.5567 - val_accuracy: 0.8527\n",
            "Epoch 33/45\n",
            "17/17 [==============================] - 3s 193ms/step - loss: 0.4101 - accuracy: 0.9557 - val_loss: 0.5532 - val_accuracy: 0.8455\n",
            "Epoch 34/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.3977 - accuracy: 0.9590 - val_loss: 0.5275 - val_accuracy: 0.8653\n",
            "Epoch 35/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.3885 - accuracy: 0.9607 - val_loss: 0.5420 - val_accuracy: 0.8477\n",
            "Epoch 36/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.3790 - accuracy: 0.9619 - val_loss: 0.5288 - val_accuracy: 0.8561\n",
            "Epoch 37/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.3728 - accuracy: 0.9612 - val_loss: 0.5067 - val_accuracy: 0.8680\n",
            "Epoch 38/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.3640 - accuracy: 0.9623 - val_loss: 0.5016 - val_accuracy: 0.8667\n",
            "Epoch 39/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.3569 - accuracy: 0.9634 - val_loss: 0.4874 - val_accuracy: 0.8722\n",
            "Epoch 40/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.3509 - accuracy: 0.9631 - val_loss: 0.5244 - val_accuracy: 0.8462\n",
            "Epoch 41/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.3433 - accuracy: 0.9643 - val_loss: 0.4793 - val_accuracy: 0.8751\n",
            "Epoch 42/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.3376 - accuracy: 0.9641 - val_loss: 0.4746 - val_accuracy: 0.8771\n",
            "Epoch 43/45\n",
            "17/17 [==============================] - 3s 191ms/step - loss: 0.3309 - accuracy: 0.9649 - val_loss: 0.4824 - val_accuracy: 0.8694\n",
            "Epoch 44/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.3371 - accuracy: 0.9578 - val_loss: 0.4890 - val_accuracy: 0.8643\n",
            "Epoch 45/45\n",
            "17/17 [==============================] - 3s 192ms/step - loss: 0.3243 - accuracy: 0.9625 - val_loss: 0.4911 - val_accuracy: 0.8581\n",
            "127/127 [==============================] - 2s 16ms/step - loss: 0.4911 - accuracy: 0.8581\n",
            "57.21560597971292 1.213920748132684 0.21946167879598538 0.4900279752339992\n",
            "load model weights_path: /content/drive/My Drive/ChestXNet Weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n",
            "<tensorflow.python.keras.engine.functional.Functional object at 0x7f183449ca58> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f1830afbfd0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f1831ad71d0> True\n",
            "Epoch 1/45\n",
            "17/17 [==============================] - 5s 270ms/step - loss: 1.0880 - accuracy: 0.3360 - val_loss: 1.0719 - val_accuracy: 0.3218\n",
            "Epoch 2/45\n",
            "17/17 [==============================] - 3s 178ms/step - loss: 1.0553 - accuracy: 0.4232 - val_loss: 1.0567 - val_accuracy: 0.4640\n",
            "Epoch 3/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 1.0138 - accuracy: 0.4936 - val_loss: 1.0518 - val_accuracy: 0.4640\n",
            "Epoch 4/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.9635 - accuracy: 0.5630 - val_loss: 1.0503 - val_accuracy: 0.4637\n",
            "Epoch 5/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.9062 - accuracy: 0.6096 - val_loss: 1.0388 - val_accuracy: 0.4654\n",
            "Epoch 6/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.8437 - accuracy: 0.6382 - val_loss: 1.0167 - val_accuracy: 0.4736\n",
            "Epoch 7/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.7935 - accuracy: 0.6463 - val_loss: 1.0007 - val_accuracy: 0.4864\n",
            "Epoch 8/45\n",
            "17/17 [==============================] - 3s 180ms/step - loss: 0.7504 - accuracy: 0.6514 - val_loss: 0.9866 - val_accuracy: 0.4970\n",
            "Epoch 9/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.7126 - accuracy: 0.6560 - val_loss: 0.9786 - val_accuracy: 0.5027\n",
            "Epoch 10/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.6859 - accuracy: 0.6570 - val_loss: 0.9895 - val_accuracy: 0.5012\n",
            "Epoch 11/45\n",
            "17/17 [==============================] - 3s 177ms/step - loss: 0.6610 - accuracy: 0.6616 - val_loss: 0.9661 - val_accuracy: 0.5190\n",
            "Epoch 12/45\n",
            "17/17 [==============================] - 3s 179ms/step - loss: 0.6428 - accuracy: 0.6645 - val_loss: 0.9543 - val_accuracy: 0.5291\n",
            "Epoch 13/45\n",
            " 7/17 [===========>..................] - ETA: 1s - loss: 0.6288 - accuracy: 0.6773"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7e2bdf16b76a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswarmsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momega\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Best position\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyswarm/pso.py\u001b[0m in \u001b[0;36mpso\u001b[0;34m(func, lb, ub, ieqcons, f_ieqcons, args, kwargs, swarmsize, omega, phip, phig, maxiter, minstep, minfunc, debug)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmark1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmark1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmark2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmark2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;31m# Compare particle's best position (if constraints are satisfied)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyswarm/pso.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Check for constraint function(s) #########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf_ieqcons\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mieqcons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e6955d50a896>\u001b[0m in \u001b[0;36mapple\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.88\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}