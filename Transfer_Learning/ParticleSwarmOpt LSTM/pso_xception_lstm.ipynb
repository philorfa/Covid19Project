{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pso_xception_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_89OwxiEP845",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "c529484e-6c8f-4fb5-8580-27eaaaf45249"
      },
      "source": [
        "!pip install --upgrade pyswarm\n",
        "!pip install pymc3\n",
        "!pip install --upgrade pactools"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pyswarm in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from pyswarm) (1.18.5)\n",
            "Requirement already satisfied: pymc3 in /usr/local/lib/python3.6/dist-packages (3.7)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pymc3) (1.0.5)\n",
            "Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.6/dist-packages (from pymc3) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from pymc3) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from pymc3) (1.4.1)\n",
            "Requirement already satisfied: theano>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from pymc3) (1.0.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pymc3) (0.5.1)\n",
            "Requirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from pymc3) (2.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pymc3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pymc3) (2.8.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from theano>=1.0.4->pymc3) (1.15.0)\n",
            "Requirement already up-to-date: pactools in /usr/local/lib/python3.6/dist-packages (0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF77qbwdn3JX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "ef07c6d2-2984-4494-8ede-c32d8bb57f64"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from pyswarm import pso\n",
        "from os import path\n",
        "import os\n",
        "import requests\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "import numpy\n",
        "import sys\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from numpy import array\n",
        "from numpy.random import choice\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import statistics\n",
        "import pandas\n",
        "import math\n",
        "import csv\n",
        "import random\n",
        "import logging\n",
        "from pymc3 import *\n",
        "import pymc3 as pm\n",
        "from functools import reduce\n",
        "from operator import add\n",
        "from tqdm import tqdm\n",
        "import geopy.distance\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from theano import shared\n",
        "from sklearn import preprocessing\n",
        "print('Running on PyMC3 v{}'.format(pm.__version__))\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "#TESNORFOW\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import datasets, layers, models\n",
        "\n",
        "#KERAS LIBRARIES\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Dropout , Flatten,BatchNormalization,Conv2D,MaxPooling2D, Activation,LSTM,Embedding,Input,GlobalAveragePooling2D\n",
        "from keras.regularizers import l1, l2, l1_l2\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend \n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import skimage.transform\n",
        "\n",
        "from numpy import savetxt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on PyMC3 v3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm-wvA6in4Av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data2():\n",
        "  train1 = np.load('/content/drive/My Drive/NumpyArrayCovidx/train.npy',allow_pickle=True)\n",
        "  train_labels1 = np.load('/content/drive/My Drive/NumpyArrayCovidx/train_labels.npy',allow_pickle=True)\n",
        "  \n",
        "  train4=np.empty([20260, 72,72,3], dtype=int)\n",
        "  \n",
        "  for i in range(len(train1)):\n",
        "    train4[i] = skimage.transform.resize(train1[i], (72, 72))\n",
        "  \n",
        "  train2,test1, train_labels2,test_labels1 = train_test_split(train4, train_labels1, test_size=0.2, random_state=42)\n",
        "  \n",
        "  x_train=train2/225.0\n",
        "  y_train = pd.get_dummies(train_labels2)\n",
        "\n",
        "  x_test=test1/225.0\n",
        "  y_test = pd.get_dummies(test_labels1)\n",
        "  return x_train,y_train,x_test,y_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsYF01Sen_GF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_test, y_test = data2()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saJNUoxKoB8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE2=(72,72,3) \n",
        "\n",
        "xception=keras.applications.xception.Xception(input_shape=IMG_SHAPE2,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgvDEZ-poCty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fine_tuning,lstm_units,dropout,learning_rate\n",
        "lb=[1,1,0.0,0.001]\n",
        "ub=[150,10,0.6,0.2]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2K0i02zoGil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_lstm_newxception(x): \n",
        "  print(x[0],x[1],x[2],x[3])\n",
        "  IMG_SHAPE2=(72,72,3) \n",
        "\n",
        "  xception=keras.applications.xception.Xception(input_shape=IMG_SHAPE2,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "  tempmod=xception\n",
        "  for layer in tempmod.layers[:(-1)*int(round(x[0]))]:\n",
        "    layer.trainable = False\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tempmod)\n",
        "  layer_2 =layers.Flatten() \n",
        "  model.add(layer_2)\n",
        "\n",
        "  model.add(layers.Reshape((layer_2.output_shape[1],1)))\n",
        "  model.add(layers.LSTM(int(round(x[1])),return_sequences=True))\n",
        "  model.add(layers.Dropout(x[2]))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(keras.layers.Dense(3,activation=\"softmax\"))\n",
        "  if x[3]< 0.003:\n",
        "    learning_rate = 0.001\n",
        "  elif x[3]< 0.0075:\n",
        "    learning_rate = 0.005\n",
        "  elif x[3]< 0.015:\n",
        "    learning_rate = 0.01\n",
        "  elif x[3]< 0.035:\n",
        "    learning_rate = 0.02\n",
        "  elif x[3]< 0.075:\n",
        "    learning_rate = 0.05\n",
        "  elif x[3]< 0.125:\n",
        "    learning_rate = 0.1\n",
        "  elif x[3]< 0.175:\n",
        "    learning_rate = 0.15\n",
        "  else:\n",
        "    learning_rate = 0.2\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIcT9eW_oWxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EarlyStopper = EarlyStopping(patience=4, monitor='val_loss', mode='min')\n",
        "count = 0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8axumDboY0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apple(x):\n",
        "  model = create_model_lstm_newxception(x)\n",
        "  model.fit(x_train, y_train, epochs=20, batch_size=1000, verbose=1,validation_data=(x_test, y_test),callbacks=[EarlyStopper])\n",
        "  loss, acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "  if acc>0.9:\n",
        "    global count \n",
        "    count = count+1\n",
        "    model.save(f\"/content/drive/My Drive/saved_models/pso_xception_lstm/model-{count}-{round(acc, 3)}-{round(loss, 3)}\")\n",
        "    savetxt(f\"/content/drive/My Drive/saved_models/pso_xception_lstm/data-{count}.csv\", x, delimiter=',')\n",
        "  return loss "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD5VZ9Oqr8LG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d60ca0d-7506-4cc2-a0e0-e86cc0884bd2"
      },
      "source": [
        "xopt, fopt = pso(apple, lb, ub, swarmsize=10, omega=0.5, phip=0.5, phig=1.0, maxiter=30, minstep=1)\n",
        "print (\"Best position\"+str(xopt))\n",
        "print (\"Loss:\" + str(fopt))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21.990429617158796 4.472921191947405 0.24487426210104468 0.0971097435435783\n",
            "Epoch 1/20\n",
            "17/17 [==============================] - 26s 2s/step - loss: 1.0885 - accuracy: 0.5160 - val_loss: 4.8438 - val_accuracy: 0.3231\n",
            "Epoch 2/20\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.5597 - accuracy: 0.8087 - val_loss: 5.1558 - val_accuracy: 0.3662\n",
            "Epoch 3/20\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.3633 - accuracy: 0.8757 - val_loss: 1.6755 - val_accuracy: 0.5972\n",
            "Epoch 4/20\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.2533 - accuracy: 0.9154 - val_loss: 1.8163 - val_accuracy: 0.5555\n",
            "Epoch 5/20\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.1915 - accuracy: 0.9346 - val_loss: 1.3774 - val_accuracy: 0.6160\n",
            "Epoch 6/20\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.1393 - accuracy: 0.9540 - val_loss: 0.7048 - val_accuracy: 0.7697\n",
            "Epoch 7/20\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.0994 - accuracy: 0.9690 - val_loss: 0.3529 - val_accuracy: 0.8783\n",
            "Epoch 8/20\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.0703 - accuracy: 0.9776 - val_loss: 0.3909 - val_accuracy: 0.8813\n",
            "Epoch 9/20\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.0592 - accuracy: 0.9809 - val_loss: 0.4161 - val_accuracy: 0.8778\n",
            "Epoch 10/20\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.0373 - accuracy: 0.9882 - val_loss: 0.4406 - val_accuracy: 0.8815\n",
            "Epoch 11/20\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.4830 - val_accuracy: 0.8717\n",
            "127/127 [==============================] - 27s 214ms/step - loss: 0.4830 - accuracy: 0.8717\n",
            "6.7767497476790455 3.7093233061384856 0.5697712515578007 0.03131712237202038\n",
            "Epoch 1/20\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.8759 - accuracy: 0.6102 - val_loss: 3.0303 - val_accuracy: 0.5479\n",
            "Epoch 2/20\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.4394 - accuracy: 0.8391 - val_loss: 1.5102 - val_accuracy: 0.6750\n",
            "Epoch 3/20\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2759 - accuracy: 0.8940 - val_loss: 0.9247 - val_accuracy: 0.7663\n",
            "Epoch 4/20\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.2075 - accuracy: 0.9213 - val_loss: 0.6010 - val_accuracy: 0.8238\n",
            "Epoch 5/20\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.1419 - accuracy: 0.9456 - val_loss: 0.4826 - val_accuracy: 0.8507\n",
            "Epoch 6/20\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.0982 - accuracy: 0.9645 - val_loss: 0.4714 - val_accuracy: 0.8517\n",
            "Epoch 7/20\n",
            "17/17 [==============================] - 22s 1s/step - loss: 0.0679 - accuracy: 0.9761 - val_loss: 0.4974 - val_accuracy: 0.8467\n",
            "Epoch 8/20\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.0445 - accuracy: 0.9859 - val_loss: 0.5736 - val_accuracy: 0.8480\n",
            "Epoch 9/20\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.0314 - accuracy: 0.9898 - val_loss: 0.5540 - val_accuracy: 0.8677\n",
            "Epoch 10/20\n",
            "17/17 [==============================] - 22s 1s/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.5905 - val_accuracy: 0.8566\n",
            "127/127 [==============================] - 27s 214ms/step - loss: 0.5905 - accuracy: 0.8566\n",
            "85.40684083121562 1.6845672605593132 0.18373428202047568 0.09617865530611686\n",
            "Epoch 1/20\n",
            "17/17 [==============================] - 34s 2s/step - loss: 0.6983 - accuracy: 0.6654 - val_loss: 2.4304 - val_accuracy: 0.6461\n",
            "Epoch 2/20\n",
            "17/17 [==============================] - 32s 2s/step - loss: 0.2340 - accuracy: 0.9186 - val_loss: 1.3447 - val_accuracy: 0.8193\n",
            "Epoch 3/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.1475 - accuracy: 0.9471 - val_loss: 1.4401 - val_accuracy: 0.8312\n",
            "Epoch 4/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0922 - accuracy: 0.9668 - val_loss: 0.8194 - val_accuracy: 0.8966\n",
            "Epoch 5/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0655 - accuracy: 0.9772 - val_loss: 0.9268 - val_accuracy: 0.8961\n",
            "Epoch 6/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0506 - accuracy: 0.9817 - val_loss: 0.7284 - val_accuracy: 0.9126\n",
            "Epoch 7/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0520 - accuracy: 0.9816 - val_loss: 1.0190 - val_accuracy: 0.8889\n",
            "Epoch 8/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.7070 - val_accuracy: 0.9131\n",
            "Epoch 9/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0267 - accuracy: 0.9907 - val_loss: 0.6590 - val_accuracy: 0.9094\n",
            "Epoch 10/20\n",
            "17/17 [==============================] - 32s 2s/step - loss: 0.0212 - accuracy: 0.9920 - val_loss: 0.5058 - val_accuracy: 0.9154\n",
            "Epoch 11/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.5405 - val_accuracy: 0.9112\n",
            "Epoch 12/20\n",
            "17/17 [==============================] - 32s 2s/step - loss: 0.0294 - accuracy: 0.9906 - val_loss: 0.5050 - val_accuracy: 0.9156\n",
            "Epoch 13/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.6050 - val_accuracy: 0.8912\n",
            "Epoch 14/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.5295 - val_accuracy: 0.9168\n",
            "Epoch 15/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.5430 - val_accuracy: 0.9198\n",
            "Epoch 16/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.4845 - val_accuracy: 0.9262\n",
            "Epoch 17/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4618 - val_accuracy: 0.9235\n",
            "Epoch 18/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.5354 - val_accuracy: 0.9038\n",
            "Epoch 19/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.5123 - val_accuracy: 0.9171\n",
            "Epoch 20/20\n",
            "17/17 [==============================] - 33s 2s/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4755 - val_accuracy: 0.9228\n",
            "127/127 [==============================] - 27s 211ms/step - loss: 0.4755 - accuracy: 0.9228\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/saved_models/pso_xception_lstm/model-1-0.923-0.476/assets\n",
            "56.64008396516943 2.909973685694405 0.5133421067570251 0.14021053095506728\n",
            "Epoch 1/20\n",
            "17/17 [==============================] - 28s 2s/step - loss: 1.0779 - accuracy: 0.4107 - val_loss: 1.0487 - val_accuracy: 0.4640\n",
            "Epoch 2/20\n",
            "17/17 [==============================] - 27s 2s/step - loss: 1.0562 - accuracy: 0.4573 - val_loss: 1.0545 - val_accuracy: 0.4640\n",
            "Epoch 3/20\n",
            "17/17 [==============================] - 27s 2s/step - loss: 1.0561 - accuracy: 0.4573 - val_loss: 1.0513 - val_accuracy: 0.4640\n",
            "Epoch 4/20\n",
            "17/17 [==============================] - 27s 2s/step - loss: 1.0551 - accuracy: 0.4573 - val_loss: 1.0518 - val_accuracy: 0.4640\n",
            "Epoch 5/20\n",
            "17/17 [==============================] - 27s 2s/step - loss: 1.0549 - accuracy: 0.4573 - val_loss: 1.0515 - val_accuracy: 0.4640\n",
            "127/127 [==============================] - 27s 211ms/step - loss: 1.0515 - accuracy: 0.4640\n",
            "129.81287027681446 4.816937243003398 0.3601234663004936 0.07422242602776839\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7e2bdf16b76a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswarmsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momega\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Best position\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyswarm/pso.py\u001b[0m in \u001b[0;36mpso\u001b[0;34m(func, lb, ub, ieqcons, f_ieqcons, args, kwargs, swarmsize, omega, phip, phig, maxiter, minstep, minfunc, debug)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Calculate the objective's value at the current particle's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mfp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# At the start, there may not be any feasible starting point, so just\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyswarm/pso.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Check for constraint function(s) #########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf_ieqcons\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mieqcons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-a81237f75bf2>\u001b[0m in \u001b[0;36mapple\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model_lstm_newxception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:    OOM when allocating tensor with shape[18432,1000,5] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node CudnnRNN}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[sequential_4/lstm_4/PartitionedCall]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_120783]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
          ]
        }
      ]
    }
  ]
}