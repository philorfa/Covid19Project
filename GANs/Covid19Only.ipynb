{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid19Only",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwJuNeOJVP19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "3fc9e4d3-c9c9-4e0c-fbca-12ac816dd89d"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 29 13:52:02 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    30W / 250W |   4659MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9APvpjJVX1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Reshape, Concatenate,ZeroPadding2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose,UpSampling2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from keras.datasets import cifar10\n",
        "import keras.backend as K\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "from sklearn.utils import shuffle\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from numpy.random import randint,randn,choice,rand\n",
        "from numpy import ones,zeros,vstack\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3rLJFbdVZ8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataset_statistics():\n",
        "  path, dirs, files = next(os.walk(\"/content/drive/My Drive/CovidxDatasetSplit/test/normal\"))\n",
        "  test_normal_count = len(files)\n",
        "  path, dirs, files = next(os.walk(\"/content/drive/My Drive/CovidxDatasetSplit/test/covid19\"))\n",
        "  test_covid19_count = len(files)\n",
        "  path, dirs, files = next(os.walk(\"/content/drive/My Drive/CovidxDatasetSplit/test/CT_COVID\"))\n",
        "  test_CT_count = len(files)\n",
        "  path, dirs, files = next(os.walk(\"/content/drive/My Drive/CovidxDatasetSplit/test/pneumonia\"))\n",
        "  test_pneumonia_count = len(files)\n",
        "\n",
        "  path, dirs, files = next(os.walk(\"/content/drive/My Drive/CovidxDatasetSplit/train/normal\"))\n",
        "  train_normal_count = len(files)\n",
        "  path, dirs, files = next(os.walk(\"/content/drive/My Drive/CovidxDatasetSplit/train/covid19\"))\n",
        "  train_covid19_count = len(files)\n",
        "  path, dirs, files = next(os.walk(\"/content/drive/My Drive/CovidxDatasetSplit/train/CT_COVID\"))\n",
        "  train_CT_count = len(files)\n",
        "  path, dirs, files = next(os.walk(\"/content/drive/My Drive/CovidxDatasetSplit/train/pneumonia\"))\n",
        "  train_pneumonia_count = len(files)\n",
        "\n",
        "  normal=test_normal_count+train_normal_count\n",
        "  covid19=test_covid19_count+train_covid19_count\n",
        "  CT=test_CT_count+train_CT_count\n",
        "  pneumonia=test_pneumonia_count+train_pneumonia_count\n",
        "\n",
        "  test_normal=test_normal_count*100/normal\n",
        "  train_normal=train_normal_count*100/normal\n",
        "\n",
        "  test_covid19=test_covid19_count*100/covid19\n",
        "  train_covid19=train_covid19_count*100/covid19\n",
        "\n",
        "  test_CT=test_CT_count*100/CT\n",
        "  train_CT=train_CT_count*100/CT\n",
        "\n",
        "  test_pneumonia=test_pneumonia_count*100/pneumonia\n",
        "  train_pneumonia=train_pneumonia_count*100/pneumonia\n",
        "\n",
        "  print(\"TEST DATASET__________TRAIN DATASET\")\n",
        "  print(\"normal =\",test_normal_count,\"          normal =\",train_normal_count)\n",
        "  print(\"covid19 =\",test_covid19_count,\"          covid19 =\",train_covid19_count)\n",
        "  print(\"CT =\",test_CT_count,\"               CT =\",train_CT_count)\n",
        "  print(\"pneumonia =\",test_pneumonia_count,\"       pneumonia =\",train_pneumonia_count)\n",
        "  print(\"covid19+CT =\",test_CT_count+test_covid19_count,\"       covid19+CT =\",train_CT_count+train_covid19_count)\n",
        "  print('\\n')\n",
        "  print(\"TEST DATASET__________TRAIN DATASET\")\n",
        "  print(\"normal =\",test_normal,\"          normal =\",train_normal)\n",
        "  print(\"covid19 =\",test_covid19,\"          covid19 =\",train_covid19)\n",
        "  print(\"CT =\",test_CT,\"               CT =\",train_CT)\n",
        "  print(\"pneumonia =\",test_pneumonia,\"       pneumonia =\",train_pneumonia)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcwbVQkHY9lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset_statistics()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq75CvITec_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = '/content/drive/My Drive/NumpyArrayCovidx'\n",
        "#BUFFER_SIZE=6000\n",
        "\n",
        "SEED_SIZE=100\n",
        "PREVIEW_ROWS = 4\n",
        "PREVIEW_COLS = 7\n",
        "PREVIEW_MARGIN = 16\n",
        "GENERATE_SQUARE =64\n",
        "CHANNELS=1\n",
        "BATCH_SIZE=32\n",
        "EPOCHS=600\n",
        "\n",
        "\n",
        "IMAGE_SHAPE=(GENERATE_SQUARE,GENERATE_SQUARE,CHANNELS)\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx8eWfEVeilS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  training_binary_path_covid_images = os.path.join(DATA_PATH,\n",
        "          f'covid19_images.npy')\n",
        "  print(\"Loading covid training pickle...\")\n",
        "  covid19_images = np.load(training_binary_path_covid_images,allow_pickle=True)\n",
        "  for i in range(len(covid19_images)):\n",
        "    covid19_images[i] = cv2.cvtColor(covid19_images[i], cv2.COLOR_BGR2RGB)\n",
        "    covid19_images[i] = cv2.resize(covid19_images[i], (GENERATE_SQUARE, GENERATE_SQUARE))\n",
        "  training_data=[]\n",
        "  for item in covid19_images:\n",
        "    if(CHANNELS==1):\n",
        "      item = np.mean(item, axis=2)\n",
        "    training_data.append(item)\n",
        "\n",
        "  train_data = np.array(training_data)\n",
        "  train_data = (train_data - 127.5) / 127.5\n",
        "  return train_data"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHvlVyzlCqqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24b3e3d0-ca1c-466c-a41f-94900a9bf437"
      },
      "source": [
        "covid19=load_data()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading covid training pickle...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSVHxYHRLdfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ac7221e-c85b-49b3-c2d8-0ee7642a4cff"
      },
      "source": [
        "covid19.shape"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(690, 64, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufh9UW_abW7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "893f9083-c5c3-490f-9010-42df1b3241aa"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(covid19[9],cmap=plt.cm.binary)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9e444ca630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjOzyF8CC268",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e0880a3-d18b-4d64-b23c-03fcb6886d32"
      },
      "source": [
        "if(CHANNELS==1):\n",
        "  covid19 = np.expand_dims(covid19, axis=3)\n",
        "covid19.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(690, 64, 64, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdz9Nsa0DVPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator():\n",
        "  model = Sequential()\n",
        "  init = RandomNormal(mean=0.0, stddev=0.02)\n",
        "  model.add(Dense(256 * 4 * 4, activation='relu',input_dim=SEED_SIZE,kernel_initializer=init))\n",
        "  model.add(BatchNormalization(momentum=0.9))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  model.add(Reshape((4, 4, 256))) #(4,4)\n",
        "  #1\n",
        "  model.add(Conv2DTranspose(128, 4, strides=2, padding='same',kernel_initializer=init))#(8,8)\n",
        "  model.add(BatchNormalization(momentum=0.9))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  #2\n",
        "  model.add(Conv2DTranspose(128, 4, strides=2, padding='same',kernel_initializer=init))#(16,16)\n",
        "  model.add(BatchNormalization(momentum=0.9))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  #3\n",
        "  model.add(Conv2DTranspose(64, 4, strides=2, padding='same',kernel_initializer=init))#(32,32)\n",
        "  model.add(BatchNormalization(momentum=0.9))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  #4\n",
        "  '''\n",
        "  model.add(Conv2DTranspose(32, 4, strides=2, padding='same',kernel_initializer=init))#(64,64)\n",
        "  model.add(BatchNormalization(momentum=0.9))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  '''\n",
        "  model.add(Conv2DTranspose(1, 4, strides=2, padding='same',kernel_initializer=init))#(128,128)\n",
        "  \n",
        "  model.add(Activation(\"tanh\"))\n",
        "  return model"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYzhmCshDbPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "outputId": "368e35cd-726b-4fc5-9adf-ebba0847b5f7"
      },
      "source": [
        "generator=get_generator()\n",
        "generator.summary()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 4096)              413696    \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_12 (Conv2DT (None, 8, 8, 128)         524416    \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_13 (Conv2DT (None, 16, 16, 128)       262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_14 (Conv2DT (None, 32, 32, 64)        131136    \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_15 (Conv2DT (None, 64, 64, 1)         1025      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 64, 64, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,350,209\n",
            "Trainable params: 1,341,377\n",
            "Non-trainable params: 8,832\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD9w0otWDg48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shape_input=(128,128,1)\n",
        "\n",
        "def get_discriminator():\n",
        "  model = Sequential()\n",
        "  init = RandomNormal(mean=0.0, stddev=0.02)\n",
        "  #1\n",
        "  model.add(Conv2D(32, kernel_size=(4,4), strides=1, padding='same',input_shape=IMAGE_SHAPE,kernel_initializer=init))#(128,128)\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  model.add(Dropout(0.25))\n",
        "  #2\n",
        "  model.add(Conv2D(64, kernel_size=(4,4), strides=2, padding='same',kernel_initializer=init))#(64,64)\n",
        "  model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "  model.add(BatchNormalization(momentum=0.9))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  model.add(Dropout(0.25))\n",
        "  #3\n",
        "  '''\n",
        "  model.add(Conv2D(128, kernel_size=(4,4), strides=2, padding='same',kernel_initializer=init))#(32,32)\n",
        "  model.add(BatchNormalization(momentum=0.9))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  model.add(Dropout(0.25))\n",
        "  '''\n",
        "  #4\n",
        "  model.add(Conv2D(128, kernel_size=(4,4), strides=2, padding='same',kernel_initializer=init))#(16,16)\n",
        "  model.add(BatchNormalization(momentum=0.9))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(256, kernel_size=(4,4), strides=2, padding='same',kernel_initializer=init))#(8,8)\n",
        "  model.add(BatchNormalization(momentum=0.9))\n",
        "  model.add(LeakyReLU(alpha=0.1))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(256*4*4, activation='relu'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "    \n",
        "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(0.0002, 0.5),metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRgZjg8mTipD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "6bc29da9-f097-4283-9114-aaafc3117748"
      },
      "source": [
        "discriminator= get_discriminator()\n",
        "discriminator.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 64, 64, 32)        544       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 64)        32832     \n",
            "_________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPaddin (None, 33, 33, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 33, 33, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 33, 33, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 17, 17, 128)       131200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 17, 17, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 9, 9, 256)         524544    \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 9, 9, 256)         1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)   (None, 9, 9, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 9, 9, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 20736)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4096)              84938752  \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 4097      \n",
            "=================================================================\n",
            "Total params: 85,633,761\n",
            "Trainable params: 85,632,865\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKFEIhhjDh6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_gan(discriminator, generator):\n",
        "    discriminator.trainable=False\n",
        "    gan_input = Input(shape=(SEED_SIZE,))\n",
        "    x = generator(gan_input)\n",
        "    gan_output= discriminator(x)\n",
        "    gan= Model(inputs=gan_input, outputs=gan_output)\n",
        "    gan.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer='adam')\n",
        "    return gan"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZZQFd1vDl6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan = create_gan(discriminator, generator)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58gaN_kODp1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(cnt,noise):\n",
        "  image_array = np.full(( \n",
        "      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
        "      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), 3), \n",
        "      255, dtype=np.uint8)\n",
        "  \n",
        "  generated_images = generator.predict(noise)\n",
        "  generated_images = 0.5 * generated_images + 0.5\n",
        "\n",
        "  image_count = 0\n",
        "  for row in range(PREVIEW_ROWS):\n",
        "      for col in range(PREVIEW_COLS):\n",
        "        r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
        "        c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
        "        image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] = generated_images[image_count] *255\n",
        "        image_count += 1\n",
        "\n",
        "          \n",
        "  output_path = os.path.join(DATA_PATH,f'Covid19GAN-{IMAGE_SHAPE}')\n",
        "  if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "  \n",
        "  filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
        "  im = Image.fromarray(image_array)\n",
        "  im.save(filename)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Puh2Rr8dDwSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def noisy_labels(y, p_flip):\n",
        "  n_select = int(p_flip * y.shape[0])\n",
        "  flip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n",
        "  y[flip_ix] = 1 - y[flip_ix]\n",
        "  return y\n",
        "\n",
        "# [0.7, 1.2]\n",
        "def smooth_positive_labels(y):\n",
        "  k = y - 0.3 + np.random.uniform(low=0.0, high=1.0, size=(y.shape)) * 0.5\n",
        "  return k\n",
        "\n",
        "#[0.0, 0.3]\n",
        "def smooth_negative_labels(y):\n",
        "  k = y + np.random.uniform(low=0.0, high=1.0, size=(y.shape)) * 0.3\n",
        "  return k\n",
        "\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "  ix = randint(0, dataset.shape[0], n_samples)\n",
        "  X = dataset[ix]\n",
        "  y = ones((n_samples, 1))\n",
        "  y = noisy_labels(y, 0.05)\n",
        "  y = smooth_positive_labels(y)\n",
        "  return X, y\n",
        "\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "  x_input = generate_latent_points(latent_dim, n_samples)\n",
        "  X = g_model.predict(x_input)\n",
        "  y = zeros((n_samples, 1))\n",
        "  y = noisy_labels(y, 0.05)\n",
        "  y=smooth_negative_labels(y)\n",
        "  return X, y\n",
        "\n",
        "def save(gan, generator, discriminator,epoch):\n",
        "    discriminator.trainable = False\n",
        "    gan.save(f\"drive/My Drive/saved_models/Covid19GAN/gan-{epoch}.h5\")\n",
        "    print(f\"GAN {epoch} SAVED\")\n",
        "    discriminator.trainable = True\n",
        "    generator.save(f\"drive/My Drive/saved_models/Covid19GAN/generator-{epoch}.h5\")\n",
        "    print(f\"Generator {epoch} SAVED\")\n",
        "    discriminator.save(f\"drive/My Drive/saved_models/Covid19GAN/discriminator-{epoch}.h5\")\n",
        "    print(f\"Discriminator {epoch} SAVED\")\n",
        "\n",
        "def save_generator(generator,epoch):\n",
        "    generator.save(f\"drive/My Drive/saved_models/Covid19GAN/generator-{epoch}.h5\")\n",
        "\n",
        "\n",
        "def train(dataset,latent_dim,g_model=generator, d_model=discriminator, gan_model=gan, n_epochs=EPOCHS , n_batch=BATCH_SIZE):\n",
        "  bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "  half_batch = int(n_batch / 2)\n",
        "  for i in range(1,n_epochs+1):\n",
        "    print(\"Epochs:\",i)\n",
        "    gan_loss_list = []\n",
        "    disc_loss_list = []\n",
        "    for j in (range(bat_per_epo)):\n",
        "      X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "      X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "      X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
        "      d_model.trainable=True\n",
        "      d_loss, _ = d_model.train_on_batch(X, y)\n",
        "      d_model.trainable=False\n",
        "      X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "      y_gan = ones((n_batch, 1))\n",
        "      #Train Twice to reduce loss\n",
        "      g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "      g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "      #print('>%d, d=%.3f, g=%.3f' % (i+1, d_loss, g_loss))\n",
        "      disc_loss_list.append(d_loss)\n",
        "      gan_loss_list.append(g_loss)\n",
        "    dloss=sum(disc_loss_list) / len(disc_loss_list)\n",
        "    ganloss=sum(gan_loss_list) / len(gan_loss_list)\n",
        "    print('discr loss = ',dloss,'gan loss = ',ganloss)\n",
        "    if(i%50==0):\n",
        "      save_images(i,X_gan)\n",
        "    if(i%100==0):\n",
        "      save_generator(g_model,i)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp2bI2brD0zP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b283ec2b-19f0-4f31-aba6-08cdc22d06bb"
      },
      "source": [
        "train(covid19,SEED_SIZE)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs: 1\n",
            "discr loss =  1.263345521120798 gan loss =  1.549786559173039\n",
            "Epochs: 2\n",
            "discr loss =  0.4169529179732005 gan loss =  0.27747490265894503\n",
            "Epochs: 3\n",
            "discr loss =  0.4300030711151305 gan loss =  0.38553437989737305\n",
            "Epochs: 4\n",
            "discr loss =  0.39091700315475464 gan loss =  0.8768525705451057\n",
            "Epochs: 5\n",
            "discr loss =  0.42935967445373535 gan loss =  0.26869220570439384\n",
            "Epochs: 6\n",
            "discr loss =  0.40783272825536276 gan loss =  1.4387526852743966\n",
            "Epochs: 7\n",
            "discr loss =  0.34727979486896876 gan loss =  1.5977169417199635\n",
            "Epochs: 8\n",
            "discr loss =  0.4842316210269928 gan loss =  0.7906603037956215\n",
            "Epochs: 9\n",
            "discr loss =  0.35363052572522846 gan loss =  1.3019666558220273\n",
            "Epochs: 10\n",
            "discr loss =  0.4310809586729322 gan loss =  1.6773818848388535\n",
            "Epochs: 11\n",
            "discr loss =  0.3738728520416078 gan loss =  1.8357872537204198\n",
            "Epochs: 12\n",
            "discr loss =  0.4157374813443139 gan loss =  1.1457753394331252\n",
            "Epochs: 13\n",
            "discr loss =  0.3685942590236664 gan loss =  0.9729422394718442\n",
            "Epochs: 14\n",
            "discr loss =  0.32414854211466654 gan loss =  1.793682683081854\n",
            "Epochs: 15\n",
            "discr loss =  0.38898855447769165 gan loss =  0.8364522634517579\n",
            "Epochs: 16\n",
            "discr loss =  0.42193321103141423 gan loss =  1.678832858800888\n",
            "Epochs: 17\n",
            "discr loss =  0.36621307333310443 gan loss =  1.7728597833996727\n",
            "Epochs: 18\n",
            "discr loss =  0.3768593697320847 gan loss =  1.3145202682131814\n",
            "Epochs: 19\n",
            "discr loss =  0.3850603295224054 gan loss =  1.7826691298257737\n",
            "Epochs: 20\n",
            "discr loss =  0.4774248160067059 gan loss =  1.1373759465558189\n",
            "Epochs: 21\n",
            "discr loss =  0.46604303802762714 gan loss =  1.5866255494100707\n",
            "Epochs: 22\n",
            "discr loss =  0.46015505705560955 gan loss =  1.651293003133365\n",
            "Epochs: 23\n",
            "discr loss =  0.40907801049096243 gan loss =  1.087465104602632\n",
            "Epochs: 24\n",
            "discr loss =  0.3666460258620126 gan loss =  2.6550203277951194\n",
            "Epochs: 25\n",
            "discr loss =  0.40582227281161715 gan loss =  1.00122384868917\n",
            "Epochs: 26\n",
            "discr loss =  0.35682077280112673 gan loss =  1.728010478473845\n",
            "Epochs: 27\n",
            "discr loss =  0.3465817804847445 gan loss =  1.361382368065062\n",
            "Epochs: 28\n",
            "discr loss =  0.4070079667227609 gan loss =  0.4820726442904699\n",
            "Epochs: 29\n",
            "discr loss =  0.37582583796410335 gan loss =  1.8592578768730164\n",
            "Epochs: 30\n",
            "discr loss =  0.4119306362810589 gan loss =  1.951654817376818\n",
            "Epochs: 31\n",
            "discr loss =  0.35488842782520114 gan loss =  1.5556793156124296\n",
            "Epochs: 32\n",
            "discr loss =  0.34574309133348013 gan loss =  0.8700611002388454\n",
            "Epochs: 33\n",
            "discr loss =  0.3728446974640801 gan loss =  1.9233360006695701\n",
            "Epochs: 34\n",
            "discr loss =  0.3566559978893825 gan loss =  2.1644475091071356\n",
            "Epochs: 35\n",
            "discr loss =  0.3787474525826318 gan loss =  0.565138884243511\n",
            "Epochs: 36\n",
            "discr loss =  0.38424364016169593 gan loss =  1.1794236799081166\n",
            "Epochs: 37\n",
            "discr loss =  0.3420486719835372 gan loss =  1.9582634710130238\n",
            "Epochs: 38\n",
            "discr loss =  0.3447658440896443 gan loss =  1.095049723273232\n",
            "Epochs: 39\n",
            "discr loss =  0.3681739746105103 gan loss =  1.3311294998441423\n",
            "Epochs: 40\n",
            "discr loss =  0.37754845477285837 gan loss =  2.0511550988469804\n",
            "Epochs: 41\n",
            "discr loss =  0.3552349699395044 gan loss =  0.9233566678705669\n",
            "Epochs: 42\n",
            "discr loss =  0.3581702077672595 gan loss =  1.209056134734835\n",
            "Epochs: 43\n",
            "discr loss =  0.3433581902867272 gan loss =  1.5627393949599493\n",
            "Epochs: 44\n",
            "discr loss =  0.32073937427429927 gan loss =  2.0903079339436124\n",
            "Epochs: 45\n",
            "discr loss =  0.35656572523571195 gan loss =  0.9756221728665488\n",
            "Epochs: 46\n",
            "discr loss =  0.38087235887845355 gan loss =  1.7722655194146293\n",
            "Epochs: 47\n",
            "discr loss =  0.3160360540662493 gan loss =  2.035914483524504\n",
            "Epochs: 48\n",
            "discr loss =  0.3484934667746226 gan loss =  0.9851801416703633\n",
            "Epochs: 49\n",
            "discr loss =  0.34852250133241924 gan loss =  0.9983962149847121\n",
            "Epochs: 50\n",
            "discr loss =  0.3736705858082998 gan loss =  2.2336008491970243\n",
            "Epochs: 51\n",
            "discr loss =  0.3559947602805637 gan loss =  1.2237135484105064\n",
            "Epochs: 52\n",
            "discr loss =  0.36260085588409785 gan loss =  1.3032921779723394\n",
            "Epochs: 53\n",
            "discr loss =  0.31724009485471816 gan loss =  1.7913601739065987\n",
            "Epochs: 54\n",
            "discr loss =  0.3418941483611152 gan loss =  1.0751985822405135\n",
            "Epochs: 55\n",
            "discr loss =  0.3375288411265328 gan loss =  0.9025557921046302\n",
            "Epochs: 56\n",
            "discr loss =  0.37189781665802 gan loss =  1.7915356613340832\n",
            "Epochs: 57\n",
            "discr loss =  0.33888239732810427 gan loss =  1.6615722747076125\n",
            "Epochs: 58\n",
            "discr loss =  0.32109020011765615 gan loss =  1.7652487187158494\n",
            "Epochs: 59\n",
            "discr loss =  0.40356355621701195 gan loss =  0.7587879910355523\n",
            "Epochs: 60\n",
            "discr loss =  0.4005579636210487 gan loss =  1.7962469117982047\n",
            "Epochs: 61\n",
            "discr loss =  0.370893908398492 gan loss =  1.896912048260371\n",
            "Epochs: 62\n",
            "discr loss =  0.33439660781905767 gan loss =  0.8831854221366701\n",
            "Epochs: 63\n",
            "discr loss =  0.3970224644456591 gan loss =  1.3387530531202043\n",
            "Epochs: 64\n",
            "discr loss =  0.38268128463200163 gan loss =  1.5617990351858593\n",
            "Epochs: 65\n",
            "discr loss =  0.3123828960316522 gan loss =  1.7991708290009272\n",
            "Epochs: 66\n",
            "discr loss =  0.3403781397002084 gan loss =  0.9209595634823754\n",
            "Epochs: 67\n",
            "discr loss =  0.3518125074250357 gan loss =  0.987700777394431\n",
            "Epochs: 68\n",
            "discr loss =  0.3550105605806623 gan loss =  1.655098015353793\n",
            "Epochs: 69\n",
            "discr loss =  0.3646718675181979 gan loss =  2.127084466673079\n",
            "Epochs: 70\n",
            "discr loss =  0.3284004011324474 gan loss =  0.9926272318476722\n",
            "Epochs: 71\n",
            "discr loss =  0.37556883479867664 gan loss =  2.2029723837262107\n",
            "Epochs: 72\n",
            "discr loss =  0.34744742867492495 gan loss =  1.996674759047372\n",
            "Epochs: 73\n",
            "discr loss =  0.366026371717453 gan loss =  1.0504674063551993\n",
            "Epochs: 74\n",
            "discr loss =  0.3287305540981747 gan loss =  0.7758057301952725\n",
            "Epochs: 75\n",
            "discr loss =  0.3385898775997616 gan loss =  1.9877593943050929\n",
            "Epochs: 76\n",
            "discr loss =  0.3919751154524939 gan loss =  1.421374180487224\n",
            "Epochs: 77\n",
            "discr loss =  0.31815330329395475 gan loss =  1.4199940874463035\n",
            "Epochs: 78\n",
            "discr loss =  0.35196763277053833 gan loss =  1.4912603100140889\n",
            "Epochs: 79\n",
            "discr loss =  0.353300568603334 gan loss =  1.7190062290146237\n",
            "Epochs: 80\n",
            "discr loss =  0.3442290893622807 gan loss =  1.2832765110901423\n",
            "Epochs: 81\n",
            "discr loss =  0.3665222426255544 gan loss =  1.3103643088113694\n",
            "Epochs: 82\n",
            "discr loss =  0.36369891677583965 gan loss =  2.176041523615519\n",
            "Epochs: 83\n",
            "discr loss =  0.32660805540425436 gan loss =  1.804268235252017\n",
            "Epochs: 84\n",
            "discr loss =  0.34073259504068465 gan loss =  1.375709484020869\n",
            "Epochs: 85\n",
            "discr loss =  0.32961533892722356 gan loss =  0.8009646421387082\n",
            "Epochs: 86\n",
            "discr loss =  0.35019810994466144 gan loss =  1.830717614718846\n",
            "Epochs: 87\n",
            "discr loss =  0.3644129903543563 gan loss =  1.6277889410654705\n",
            "Epochs: 88\n",
            "discr loss =  0.3645927423522586 gan loss =  1.4865781182334536\n",
            "Epochs: 89\n",
            "discr loss =  0.3667119826589312 gan loss =  1.9508450740859622\n",
            "Epochs: 90\n",
            "discr loss =  0.3516189931404023 gan loss =  0.7086579728694189\n",
            "Epochs: 91\n",
            "discr loss =  0.38397179614929927 gan loss =  1.5210092890830267\n",
            "Epochs: 92\n",
            "discr loss =  0.3552584151426951 gan loss =  1.8050231082098824\n",
            "Epochs: 93\n",
            "discr loss =  0.35104560426303316 gan loss =  1.9682595268601464\n",
            "Epochs: 94\n",
            "discr loss =  0.34756989777088165 gan loss =  1.7278639816102528\n",
            "Epochs: 95\n",
            "discr loss =  0.3515007020462127 gan loss =  1.2207230173406147\n",
            "Epochs: 96\n",
            "discr loss =  0.3624703564814159 gan loss =  2.0898768390927995\n",
            "Epochs: 97\n",
            "discr loss =  0.3607399073385057 gan loss =  1.4536125773475284\n",
            "Epochs: 98\n",
            "discr loss =  0.38116403278850375 gan loss =  1.527041060583932\n",
            "Epochs: 99\n",
            "discr loss =  0.35156913314546856 gan loss =  1.8100954180672055\n",
            "Epochs: 100\n",
            "discr loss =  0.3099475105603536 gan loss =  1.780936490921747\n",
            "Epochs: 101\n",
            "discr loss =  0.33041733787173316 gan loss =  1.678960607165382\n",
            "Epochs: 102\n",
            "discr loss =  0.3451772247041975 gan loss =  0.9435712737696511\n",
            "Epochs: 103\n",
            "discr loss =  0.3618847685200827 gan loss =  1.4149923977397738\n",
            "Epochs: 104\n",
            "discr loss =  0.33807764166877385 gan loss =  2.006159319764092\n",
            "Epochs: 105\n",
            "discr loss =  0.33528155656087966 gan loss =  0.634139229853948\n",
            "Epochs: 106\n",
            "discr loss =  0.34711348371846334 gan loss =  1.476668743860154\n",
            "Epochs: 107\n",
            "discr loss =  0.3675613609098253 gan loss =  1.884562923794701\n",
            "Epochs: 108\n",
            "discr loss =  0.36563432145686375 gan loss =  1.4634906167075747\n",
            "Epochs: 109\n",
            "discr loss =  0.3370590288014639 gan loss =  2.0524009466171265\n",
            "Epochs: 110\n",
            "discr loss =  0.36866615357853116 gan loss =  1.4569941787492662\n",
            "Epochs: 111\n",
            "discr loss =  0.3568088873511269 gan loss =  1.7081524843261355\n",
            "Epochs: 112\n",
            "discr loss =  0.33442257060891106 gan loss =  1.87961646204903\n",
            "Epochs: 113\n",
            "discr loss =  0.3677966346343358 gan loss =  0.7268914814506259\n",
            "Epochs: 114\n",
            "discr loss =  0.34053985419727506 gan loss =  1.338212782428378\n",
            "Epochs: 115\n",
            "discr loss =  0.3211587142376673 gan loss =  1.8864508441516332\n",
            "Epochs: 116\n",
            "discr loss =  0.3350476799976258 gan loss =  1.5855527846586137\n",
            "Epochs: 117\n",
            "discr loss =  0.32929706147738863 gan loss =  1.4273258433455513\n",
            "Epochs: 118\n",
            "discr loss =  0.3675891615095593 gan loss =  1.6853179250444685\n",
            "Epochs: 119\n",
            "discr loss =  0.3438100914160411 gan loss =  1.2691834593812625\n",
            "Epochs: 120\n",
            "discr loss =  0.32065735118729727 gan loss =  1.5650629770188105\n",
            "Epochs: 121\n",
            "discr loss =  0.3422115047772725 gan loss =  1.6883258791196913\n",
            "Epochs: 122\n",
            "discr loss =  0.35742924894605366 gan loss =  1.575695500487373\n",
            "Epochs: 123\n",
            "discr loss =  0.3425010357584272 gan loss =  0.8693543573220571\n",
            "Epochs: 124\n",
            "discr loss =  0.3593999133223579 gan loss =  1.8758266880398704\n",
            "Epochs: 125\n",
            "discr loss =  0.34035642941792804 gan loss =  0.8986191075472605\n",
            "Epochs: 126\n",
            "discr loss =  0.3596730899243128 gan loss =  0.9839424647036052\n",
            "Epochs: 127\n",
            "discr loss =  0.3642254840760004 gan loss =  1.915560830207098\n",
            "Epochs: 128\n",
            "discr loss =  0.3630058140981765 gan loss =  1.9719467702366056\n",
            "Epochs: 129\n",
            "discr loss =  0.3616571639265333 gan loss =  1.2886953495797657\n",
            "Epochs: 130\n",
            "discr loss =  0.33642623254231047 gan loss =  1.463550627231598\n",
            "Epochs: 131\n",
            "discr loss =  0.35657403085912975 gan loss =  1.8121508672123863\n",
            "Epochs: 132\n",
            "discr loss =  0.37480442296890987 gan loss =  1.8013623328435988\n",
            "Epochs: 133\n",
            "discr loss =  0.3626083220754351 gan loss =  1.648486859741665\n",
            "Epochs: 134\n",
            "discr loss =  0.35749416550000507 gan loss =  2.0545144762311662\n",
            "Epochs: 135\n",
            "discr loss =  0.38145515748432707 gan loss =  1.213774588136446\n",
            "Epochs: 136\n",
            "discr loss =  0.3737213412920634 gan loss =  1.8028410048711867\n",
            "Epochs: 137\n",
            "discr loss =  0.32866541260764714 gan loss =  1.961600655601138\n",
            "Epochs: 138\n",
            "discr loss =  0.35167836362407323 gan loss =  1.4480399602935428\n",
            "Epochs: 139\n",
            "discr loss =  0.32801074924923124 gan loss =  1.7653374558403379\n",
            "Epochs: 140\n",
            "discr loss =  0.341260273541723 gan loss =  0.899452571712789\n",
            "Epochs: 141\n",
            "discr loss =  0.3630433671531223 gan loss =  0.9836575729506356\n",
            "Epochs: 142\n",
            "discr loss =  0.3590747614701589 gan loss =  1.0052643219629924\n",
            "Epochs: 143\n",
            "discr loss =  0.357262915798596 gan loss =  1.1598482068095888\n",
            "Epochs: 144\n",
            "discr loss =  0.3334821647121793 gan loss =  0.9551993792965299\n",
            "Epochs: 145\n",
            "discr loss =  0.35229188487643287 gan loss =  1.577455724988665\n",
            "Epochs: 146\n",
            "discr loss =  0.34117500200158074 gan loss =  1.2010807238873982\n",
            "Epochs: 147\n",
            "discr loss =  0.34576810115859624 gan loss =  1.6062742925825573\n",
            "Epochs: 148\n",
            "discr loss =  0.3667320325261071 gan loss =  1.7544511159261067\n",
            "Epochs: 149\n",
            "discr loss =  0.33442056675752 gan loss =  1.2511675244285947\n",
            "Epochs: 150\n",
            "discr loss =  0.31386537069366094 gan loss =  2.0695277736300515\n",
            "Epochs: 151\n",
            "discr loss =  0.3471922108105251 gan loss =  0.8833703689631962\n",
            "Epochs: 152\n",
            "discr loss =  0.3512003890105656 gan loss =  1.209981225785755\n",
            "Epochs: 153\n",
            "discr loss =  0.3627835185754867 gan loss =  1.8196811562492734\n",
            "Epochs: 154\n",
            "discr loss =  0.3363894188687915 gan loss =  1.4132165028935386\n",
            "Epochs: 155\n",
            "discr loss =  0.3691715768405369 gan loss =  1.6263328960963659\n",
            "Epochs: 156\n",
            "discr loss =  0.3446267985162281 gan loss =  1.7920849663870675\n",
            "Epochs: 157\n",
            "discr loss =  0.3453663055385862 gan loss =  1.6882967750231426\n",
            "Epochs: 158\n",
            "discr loss =  0.3588210911977859 gan loss =  1.3007704076312838\n",
            "Epochs: 159\n",
            "discr loss =  0.33604890888645533 gan loss =  2.1055026281447637\n",
            "Epochs: 160\n",
            "discr loss =  0.3507383572203772 gan loss =  1.6556933465458097\n",
            "Epochs: 161\n",
            "discr loss =  0.35833897973809925 gan loss =  0.9934229737236386\n",
            "Epochs: 162\n",
            "discr loss =  0.3978383370808193 gan loss =  1.7922173085666837\n",
            "Epochs: 163\n",
            "discr loss =  0.35356795220147996 gan loss =  1.8032691649028234\n",
            "Epochs: 164\n",
            "discr loss =  0.3283193693274543 gan loss =  0.85704747906753\n",
            "Epochs: 165\n",
            "discr loss =  0.36183426067942664 gan loss =  1.2499788517043704\n",
            "Epochs: 166\n",
            "discr loss =  0.3605822239603315 gan loss =  1.8031381907917203\n",
            "Epochs: 167\n",
            "discr loss =  0.3694392265308471 gan loss =  2.054371725945246\n",
            "Epochs: 168\n",
            "discr loss =  0.35150973427863347 gan loss =  1.0305963087649572\n",
            "Epochs: 169\n",
            "discr loss =  0.36670537789662677 gan loss =  1.3432931162062145\n",
            "Epochs: 170\n",
            "discr loss =  0.3547401669479552 gan loss =  2.0037718386877152\n",
            "Epochs: 171\n",
            "discr loss =  0.3168137477976935 gan loss =  1.6673466776098524\n",
            "Epochs: 172\n",
            "discr loss =  0.3518610078664053 gan loss =  1.677945369765872\n",
            "Epochs: 173\n",
            "discr loss =  0.33772379585674833 gan loss =  1.9696180763698758\n",
            "Epochs: 174\n",
            "discr loss =  0.34402412247090114 gan loss =  1.4466081119719005\n",
            "Epochs: 175\n",
            "discr loss =  0.3565278848012288 gan loss =  1.6141343258676075\n",
            "Epochs: 176\n",
            "discr loss =  0.3379495619308381 gan loss =  1.9542729741051084\n",
            "Epochs: 177\n",
            "discr loss =  0.3546908852599916 gan loss =  1.9276785481543768\n",
            "Epochs: 178\n",
            "discr loss =  0.3329476040034067 gan loss =  1.232564600450652\n",
            "Epochs: 179\n",
            "discr loss =  0.37372903241997674 gan loss =  1.833953130812872\n",
            "Epochs: 180\n",
            "discr loss =  0.32908772428830463 gan loss =  1.8616560356957572\n",
            "Epochs: 181\n",
            "discr loss =  0.3327686602161044 gan loss =  1.9045172759464808\n",
            "Epochs: 182\n",
            "discr loss =  0.3525489057813372 gan loss =  1.513784028234936\n",
            "Epochs: 183\n",
            "discr loss =  0.3777210080907458 gan loss =  1.7173982007162911\n",
            "Epochs: 184\n",
            "discr loss =  0.3562728365262349 gan loss =  1.8708372626985823\n",
            "Epochs: 185\n",
            "discr loss =  0.3533618833337511 gan loss =  1.6606361638932001\n",
            "Epochs: 186\n",
            "discr loss =  0.34872473776340485 gan loss =  1.9628211146309262\n",
            "Epochs: 187\n",
            "discr loss =  0.3330028120960508 gan loss =  1.1977275751885914\n",
            "Epochs: 188\n",
            "discr loss =  0.3290797599724361 gan loss =  1.2062247367132277\n",
            "Epochs: 189\n",
            "discr loss =  0.3399158205304827 gan loss =  1.6344450201307024\n",
            "Epochs: 190\n",
            "discr loss =  0.352717467716762 gan loss =  1.7977541528996968\n",
            "Epochs: 191\n",
            "discr loss =  0.3565685394264403 gan loss =  1.5142042409806025\n",
            "Epochs: 192\n",
            "discr loss =  0.3609705255145118 gan loss =  1.9609268761816478\n",
            "Epochs: 193\n",
            "discr loss =  0.3233446131149928 gan loss =  2.1166556222098216\n",
            "Epochs: 194\n",
            "discr loss =  0.34112795903569176 gan loss =  1.3282270686967033\n",
            "Epochs: 195\n",
            "discr loss =  0.36649539853845325 gan loss =  1.7441072350456601\n",
            "Epochs: 196\n",
            "discr loss =  0.33898049876803443 gan loss =  1.8520490725835164\n",
            "Epochs: 197\n",
            "discr loss =  0.3630421204226358 gan loss =  1.9474067006792342\n",
            "Epochs: 198\n",
            "discr loss =  0.3608727284840175 gan loss =  1.2357119520505269\n",
            "Epochs: 199\n",
            "discr loss =  0.3474076574756986 gan loss =  1.547646159217471\n",
            "Epochs: 200\n",
            "discr loss =  0.3424206234159924 gan loss =  2.0507836171558926\n",
            "Epochs: 201\n",
            "discr loss =  0.33811131971223013 gan loss =  1.5410685113498144\n",
            "Epochs: 202\n",
            "discr loss =  0.3658126408145541 gan loss =  0.9683022754532951\n",
            "Epochs: 203\n",
            "discr loss =  0.3666880698431106 gan loss =  1.7226561137608118\n",
            "Epochs: 204\n",
            "discr loss =  0.35411234767664046 gan loss =  1.4778141038758414\n",
            "Epochs: 205\n",
            "discr loss =  0.3591647474538712 gan loss =  1.119861247993651\n",
            "Epochs: 206\n",
            "discr loss =  0.3475766394819532 gan loss =  2.027768600554693\n",
            "Epochs: 207\n",
            "discr loss =  0.34371356949919746 gan loss =  1.6053418971243358\n",
            "Epochs: 208\n",
            "discr loss =  0.34275443851947784 gan loss =  1.8004714335714067\n",
            "Epochs: 209\n",
            "discr loss =  0.3396306790056683 gan loss =  1.398631853716714\n",
            "Epochs: 210\n",
            "discr loss =  0.3754352600801559 gan loss =  1.4070653035527183\n",
            "Epochs: 211\n",
            "discr loss =  0.35384240604582284 gan loss =  1.9604383820579165\n",
            "Epochs: 212\n",
            "discr loss =  0.3396151896033968 gan loss =  1.2798216286159696\n",
            "Epochs: 213\n",
            "discr loss =  0.38623994234062375 gan loss =  1.6844177331243242\n",
            "Epochs: 214\n",
            "discr loss =  0.3114717709166663 gan loss =  1.9467755215508598\n",
            "Epochs: 215\n",
            "discr loss =  0.3255621450287955 gan loss =  1.1550057381391525\n",
            "Epochs: 216\n",
            "discr loss =  0.3404430690265837 gan loss =  0.2764635306029093\n",
            "Epochs: 217\n",
            "discr loss =  0.3519529380968639 gan loss =  1.5631254655974252\n",
            "Epochs: 218\n",
            "discr loss =  0.37914005915323895 gan loss =  1.7231589498974027\n",
            "Epochs: 219\n",
            "discr loss =  0.33502315126714255 gan loss =  1.307714072721345\n",
            "Epochs: 220\n",
            "discr loss =  0.3708951146829696 gan loss =  1.1184220853305997\n",
            "Epochs: 221\n",
            "discr loss =  0.3700066925514312 gan loss =  1.488743862935475\n",
            "Epochs: 222\n",
            "discr loss =  0.3558509967156819 gan loss =  1.8985097805658977\n",
            "Epochs: 223\n",
            "discr loss =  0.36347285622642156 gan loss =  1.824362283661252\n",
            "Epochs: 224\n",
            "discr loss =  0.3495544549964723 gan loss =  1.2132321851594108\n",
            "Epochs: 225\n",
            "discr loss =  0.3764298465989885 gan loss =  1.929236650466919\n",
            "Epochs: 226\n",
            "discr loss =  0.3453182883205868 gan loss =  1.31119647196361\n",
            "Epochs: 227\n",
            "discr loss =  0.34099328375997995 gan loss =  1.8347399064472742\n",
            "Epochs: 228\n",
            "discr loss =  0.33454236672038123 gan loss =  0.9076074886889685\n",
            "Epochs: 229\n",
            "discr loss =  0.34399863864694324 gan loss =  1.704598756063552\n",
            "Epochs: 230\n",
            "discr loss =  0.3838964913572584 gan loss =  1.9355042661939348\n",
            "Epochs: 231\n",
            "discr loss =  0.33816360788685934 gan loss =  1.8800995349884033\n",
            "Epochs: 232\n",
            "discr loss =  0.3578043665204729 gan loss =  2.069436501889002\n",
            "Epochs: 233\n",
            "discr loss =  0.35775093237559 gan loss =  1.9908564317794073\n",
            "Epochs: 234\n",
            "discr loss =  0.3457907239596049 gan loss =  0.7552945691914785\n",
            "Epochs: 235\n",
            "discr loss =  0.3590475718180339 gan loss =  1.3361941774686177\n",
            "Epochs: 236\n",
            "discr loss =  0.3541837731997172 gan loss =  1.8555977514811925\n",
            "Epochs: 237\n",
            "discr loss =  0.37330296351796105 gan loss =  1.4145719792161668\n",
            "Epochs: 238\n",
            "discr loss =  0.328117793514615 gan loss =  1.675405434199742\n",
            "Epochs: 239\n",
            "discr loss =  0.33029333750406903 gan loss =  1.5913070298376537\n",
            "Epochs: 240\n",
            "discr loss =  0.3471001216343471 gan loss =  0.7891315207594917\n",
            "Epochs: 241\n",
            "discr loss =  0.3541117495014554 gan loss =  2.006389617919922\n",
            "Epochs: 242\n",
            "discr loss =  0.336127574245135 gan loss =  2.0481382267815724\n",
            "Epochs: 243\n",
            "discr loss =  0.33717482572510127 gan loss =  1.8797783965156192\n",
            "Epochs: 244\n",
            "discr loss =  0.35358837956473943 gan loss =  1.1820027516001748\n",
            "Epochs: 245\n",
            "discr loss =  0.3580785322756994 gan loss =  1.513197192123958\n",
            "Epochs: 246\n",
            "discr loss =  0.37029401177451726 gan loss =  1.9201330230349587\n",
            "Epochs: 247\n",
            "discr loss =  0.3313684023561932 gan loss =  1.7960223867779685\n",
            "Epochs: 248\n",
            "discr loss =  0.3507440196616309 gan loss =  2.113629727136521\n",
            "Epochs: 249\n",
            "discr loss =  0.3473284280016309 gan loss =  1.8008873349144345\n",
            "Epochs: 250\n",
            "discr loss =  0.3480843710047858 gan loss =  1.143455567814055\n",
            "Epochs: 251\n",
            "discr loss =  0.3549742954117911 gan loss =  1.7961419877551852\n",
            "Epochs: 252\n",
            "discr loss =  0.34517482419808704 gan loss =  2.0798231874193465\n",
            "Epochs: 253\n",
            "discr loss =  0.3242701767455964 gan loss =  1.5775585089411055\n",
            "Epochs: 254\n",
            "discr loss =  0.35934491952260333 gan loss =  0.7698645889759064\n",
            "Epochs: 255\n",
            "discr loss =  0.3063841455039524 gan loss =  1.317604905083066\n",
            "Epochs: 256\n",
            "discr loss =  0.34112115842955454 gan loss =  1.767076693830036\n",
            "Epochs: 257\n",
            "discr loss =  0.34552199358031865 gan loss =  1.7929975872948056\n",
            "Epochs: 258\n",
            "discr loss =  0.33942530836377827 gan loss =  1.2935039613928114\n",
            "Epochs: 259\n",
            "discr loss =  0.34203249996616725 gan loss =  0.8580222122725987\n",
            "Epochs: 260\n",
            "discr loss =  0.3591670024962652 gan loss =  1.5659353960128057\n",
            "Epochs: 261\n",
            "discr loss =  0.35058712249710444 gan loss =  2.0665088154020763\n",
            "Epochs: 262\n",
            "discr loss =  0.3489411700339544 gan loss =  1.5109328201838903\n",
            "Epochs: 263\n",
            "discr loss =  0.34175901611646015 gan loss =  1.2165306877522242\n",
            "Epochs: 264\n",
            "discr loss =  0.33795240166641416 gan loss =  1.9347835325059437\n",
            "Epochs: 265\n",
            "discr loss =  0.3562218788124266 gan loss =  1.4802627847308205\n",
            "Epochs: 266\n",
            "discr loss =  0.37870932051113676 gan loss =  1.5443977174304782\n",
            "Epochs: 267\n",
            "discr loss =  0.32634879648685455 gan loss =  1.8688250723339261\n",
            "Epochs: 268\n",
            "discr loss =  0.3584845449243273 gan loss =  1.7290228349821908\n",
            "Epochs: 269\n",
            "discr loss =  0.3626205452850887 gan loss =  1.4765622445515223\n",
            "Epochs: 270\n",
            "discr loss =  0.34041014810403186 gan loss =  1.5643559410458518\n",
            "Epochs: 271\n",
            "discr loss =  0.3502798428138097 gan loss =  2.0068280526569913\n",
            "Epochs: 272\n",
            "discr loss =  0.34778952456655954 gan loss =  2.039334257443746\n",
            "Epochs: 273\n",
            "discr loss =  0.3487021454742977 gan loss =  1.2697230322020394\n",
            "Epochs: 274\n",
            "discr loss =  0.33717466748896097 gan loss =  0.9924693873950413\n",
            "Epochs: 275\n",
            "discr loss =  0.34519140067554654 gan loss =  2.006166100502014\n",
            "Epochs: 276\n",
            "discr loss =  0.35401760041713715 gan loss =  1.5690443004880632\n",
            "Epochs: 277\n",
            "discr loss =  0.3432113130887349 gan loss =  1.1285148575192405\n",
            "Epochs: 278\n",
            "discr loss =  0.3486930898257664 gan loss =  1.8750942548116047\n",
            "Epochs: 279\n",
            "discr loss =  0.381112019220988 gan loss =  1.9650201911018008\n",
            "Epochs: 280\n",
            "discr loss =  0.3647812661670503 gan loss =  2.0407213256472634\n",
            "Epochs: 281\n",
            "discr loss =  0.3250955201330639 gan loss =  1.2798979466869718\n",
            "Epochs: 282\n",
            "discr loss =  0.36194505223206114 gan loss =  1.5479700338272822\n",
            "Epochs: 283\n",
            "discr loss =  0.3704355288119543 gan loss =  1.7957270883378529\n",
            "Epochs: 284\n",
            "discr loss =  0.3446329754023325 gan loss =  1.1147442091078985\n",
            "Epochs: 285\n",
            "discr loss =  0.3499229827097484 gan loss =  1.8479341382072085\n",
            "Epochs: 286\n",
            "discr loss =  0.3442879368861516 gan loss =  1.957857506615775\n",
            "Epochs: 287\n",
            "discr loss =  0.3410040097577231 gan loss =  2.0323004609062556\n",
            "Epochs: 288\n",
            "discr loss =  0.33405059576034546 gan loss =  1.1308648132142567\n",
            "Epochs: 289\n",
            "discr loss =  0.361010974361783 gan loss =  1.4413760531516302\n",
            "Epochs: 290\n",
            "discr loss =  0.3347229240905671 gan loss =  1.9166861772537231\n",
            "Epochs: 291\n",
            "discr loss =  0.3556713241906393 gan loss =  1.7956732908884685\n",
            "Epochs: 292\n",
            "discr loss =  0.34274155611083623 gan loss =  1.7651524884360177\n",
            "Epochs: 293\n",
            "discr loss =  0.34921367324533914 gan loss =  1.7871787931237901\n",
            "Epochs: 294\n",
            "discr loss =  0.32521228918007444 gan loss =  1.7137147699083601\n",
            "Epochs: 295\n",
            "discr loss =  0.31935798767067136 gan loss =  1.7596136388324557\n",
            "Epochs: 296\n",
            "discr loss =  0.3194640729398954 gan loss =  0.35979296550864265\n",
            "Epochs: 297\n",
            "discr loss =  0.35623769887856077 gan loss =  1.2778122297355108\n",
            "Epochs: 298\n",
            "discr loss =  0.3627989206995283 gan loss =  2.0848117782956077\n",
            "Epochs: 299\n",
            "discr loss =  0.3348250183321181 gan loss =  1.58913935366131\n",
            "Epochs: 300\n",
            "discr loss =  0.3649259479272933 gan loss =  1.620551205816723\n",
            "Epochs: 301\n",
            "discr loss =  0.357452997139522 gan loss =  1.8683710211799258\n",
            "Epochs: 302\n",
            "discr loss =  0.3591227119877225 gan loss =  1.9136978671664284\n",
            "Epochs: 303\n",
            "discr loss =  0.3564858337243398 gan loss =  1.5944121536754428\n",
            "Epochs: 304\n",
            "discr loss =  0.3712558554751532 gan loss =  1.7252212166786194\n",
            "Epochs: 305\n",
            "discr loss =  0.3546191808723268 gan loss =  1.4213879108428955\n",
            "Epochs: 306\n",
            "discr loss =  0.3405089584134874 gan loss =  1.6515988962990897\n",
            "Epochs: 307\n",
            "discr loss =  0.35876502309526714 gan loss =  1.8088926303954351\n",
            "Epochs: 308\n",
            "discr loss =  0.3340689717304139 gan loss =  1.9457500548589797\n",
            "Epochs: 309\n",
            "discr loss =  0.344893060979389 gan loss =  1.7516477335067022\n",
            "Epochs: 310\n",
            "discr loss =  0.33091612727869124 gan loss =  0.6122762326683316\n",
            "Epochs: 311\n",
            "discr loss =  0.34428245751630693 gan loss =  1.3597207409994942\n",
            "Epochs: 312\n",
            "discr loss =  0.35702073715981986 gan loss =  1.7333377628099351\n",
            "Epochs: 313\n",
            "discr loss =  0.31363200006030856 gan loss =  1.6402401299703688\n",
            "Epochs: 314\n",
            "discr loss =  0.370809154851096 gan loss =  1.2418763353711082\n",
            "Epochs: 315\n",
            "discr loss =  0.3386069642645972 gan loss =  1.8937230450766427\n",
            "Epochs: 316\n",
            "discr loss =  0.3257742602200735 gan loss =  1.4801732741651081\n",
            "Epochs: 317\n",
            "discr loss =  0.3675514303502582 gan loss =  1.0374938817251296\n",
            "Epochs: 318\n",
            "discr loss =  0.3565447394336973 gan loss =  1.9816772370111375\n",
            "Epochs: 319\n",
            "discr loss =  0.34223972048078266 gan loss =  1.9555504378818331\n",
            "Epochs: 320\n",
            "discr loss =  0.3477313688823155 gan loss =  1.7905553011667161\n",
            "Epochs: 321\n",
            "discr loss =  0.3201033004692623 gan loss =  2.026787139120556\n",
            "Epochs: 322\n",
            "discr loss =  0.3316808896405356 gan loss =  0.8292308832917895\n",
            "Epochs: 323\n",
            "discr loss =  0.3729333302804402 gan loss =  1.3837811890102567\n",
            "Epochs: 324\n",
            "discr loss =  0.34742757039410727 gan loss =  1.9844945385342552\n",
            "Epochs: 325\n",
            "discr loss =  0.3331697200025831 gan loss =  0.786640352791264\n",
            "Epochs: 326\n",
            "discr loss =  0.32740173311460585 gan loss =  1.4249979456265767\n",
            "Epochs: 327\n",
            "discr loss =  0.3420960165205456 gan loss =  2.026300753865923\n",
            "Epochs: 328\n",
            "discr loss =  0.3497371446518671 gan loss =  2.100288294610523\n",
            "Epochs: 329\n",
            "discr loss =  0.36899160345395404 gan loss =  1.340577020531609\n",
            "Epochs: 330\n",
            "discr loss =  0.3325989693403244 gan loss =  1.6363768038295565\n",
            "Epochs: 331\n",
            "discr loss =  0.36905093491077423 gan loss =  1.7403381211417062\n",
            "Epochs: 332\n",
            "discr loss =  0.36282301091012503 gan loss =  1.9486064967655001\n",
            "Epochs: 333\n",
            "discr loss =  0.36944706383205594 gan loss =  1.994166096051534\n",
            "Epochs: 334\n",
            "discr loss =  0.3304734989291146 gan loss =  0.7808137596363113\n",
            "Epochs: 335\n",
            "discr loss =  0.34417514432044255 gan loss =  1.6915826542036874\n",
            "Epochs: 336\n",
            "discr loss =  0.3306148477963039 gan loss =  1.5953452530361356\n",
            "Epochs: 337\n",
            "discr loss =  0.3481824213550204 gan loss =  1.6931082691465105\n",
            "Epochs: 338\n",
            "discr loss =  0.3291373061282294 gan loss =  1.9808067423956734\n",
            "Epochs: 339\n",
            "discr loss =  0.3343275409369242 gan loss =  1.904205078170413\n",
            "Epochs: 340\n",
            "discr loss =  0.3481927116711934 gan loss =  1.5447382416043962\n",
            "Epochs: 341\n",
            "discr loss =  0.3322585508936927 gan loss =  1.5913443905966622\n",
            "Epochs: 342\n",
            "discr loss =  0.3221362367981956 gan loss =  1.6442807511914344\n",
            "Epochs: 343\n",
            "discr loss =  0.33427959041936056 gan loss =  0.634571156331471\n",
            "Epochs: 344\n",
            "discr loss =  0.33297883967558545 gan loss =  1.480712095896403\n",
            "Epochs: 345\n",
            "discr loss =  0.32376144400664736 gan loss =  1.6849859669094993\n",
            "Epochs: 346\n",
            "discr loss =  0.33756013427461895 gan loss =  1.4675767833278293\n",
            "Epochs: 347\n",
            "discr loss =  0.3599905031067984 gan loss =  1.208477801510266\n",
            "Epochs: 348\n",
            "discr loss =  0.34912016420137315 gan loss =  1.7041296845390683\n",
            "Epochs: 349\n",
            "discr loss =  0.34439623072033837 gan loss =  1.9909148386546545\n",
            "Epochs: 350\n",
            "discr loss =  0.3374639863059634 gan loss =  1.7056898162478493\n",
            "Epochs: 351\n",
            "discr loss =  0.3484828741777511 gan loss =  0.9334700944877806\n",
            "Epochs: 352\n",
            "discr loss =  0.3600274970134099 gan loss =  1.48654290891829\n",
            "Epochs: 353\n",
            "discr loss =  0.335231350291343 gan loss =  1.750547902924674\n",
            "Epochs: 354\n",
            "discr loss =  0.33493624059926896 gan loss =  1.4653863608837128\n",
            "Epochs: 355\n",
            "discr loss =  0.3521086091086978 gan loss =  1.0020691028663091\n",
            "Epochs: 356\n",
            "discr loss =  0.3299985258352189 gan loss =  1.5953531293641954\n",
            "Epochs: 357\n",
            "discr loss =  0.3691531533286685 gan loss =  1.6538029682068598\n",
            "Epochs: 358\n",
            "discr loss =  0.33910793704645975 gan loss =  1.2406619730449857\n",
            "Epochs: 359\n",
            "discr loss =  0.3382690882398969 gan loss =  1.94931537764413\n",
            "Epochs: 360\n",
            "discr loss =  0.3360346257686615 gan loss =  1.5092262824376423\n",
            "Epochs: 361\n",
            "discr loss =  0.3750206090155102 gan loss =  1.7189216727302188\n",
            "Epochs: 362\n",
            "discr loss =  0.36190731255781083 gan loss =  1.679016845566886\n",
            "Epochs: 363\n",
            "discr loss =  0.3540953312601362 gan loss =  1.710614684082213\n",
            "Epochs: 364\n",
            "discr loss =  0.3553342237359002 gan loss =  1.4947875170480638\n",
            "Epochs: 365\n",
            "discr loss =  0.3539167968999772 gan loss =  1.5604441563288372\n",
            "Epochs: 366\n",
            "discr loss =  0.36623271377313704 gan loss =  1.6661271708352225\n",
            "Epochs: 367\n",
            "discr loss =  0.33928534672373817 gan loss =  1.8466376066207886\n",
            "Epochs: 368\n",
            "discr loss =  0.32997142984753564 gan loss =  1.9467433463959467\n",
            "Epochs: 369\n",
            "discr loss =  0.33137511426494237 gan loss =  0.7453896807772773\n",
            "Epochs: 370\n",
            "discr loss =  0.3179435410669872 gan loss =  0.8531761666138967\n",
            "Epochs: 371\n",
            "discr loss =  0.3568226198355357 gan loss =  1.8984483480453491\n",
            "Epochs: 372\n",
            "discr loss =  0.3665469927447183 gan loss =  2.0187221254621233\n",
            "Epochs: 373\n",
            "discr loss =  0.334036539707865 gan loss =  0.9756263160989398\n",
            "Epochs: 374\n",
            "discr loss =  0.3171783508289428 gan loss =  0.9723775102978661\n",
            "Epochs: 375\n",
            "discr loss =  0.3319218485128312 gan loss =  1.4657221322967893\n",
            "Epochs: 376\n",
            "discr loss =  0.35810451422418865 gan loss =  0.87480790132568\n",
            "Epochs: 377\n",
            "discr loss =  0.34007408505394343 gan loss =  1.2069703283764066\n",
            "Epochs: 378\n",
            "discr loss =  0.3387895581268129 gan loss =  1.7316755680810838\n",
            "Epochs: 379\n",
            "discr loss =  0.3531819312345414 gan loss =  2.110741677738371\n",
            "Epochs: 380\n",
            "discr loss =  0.34796400368213654 gan loss =  1.8092414197467623\n",
            "Epochs: 381\n",
            "discr loss =  0.34027380035037086 gan loss =  0.930297002905891\n",
            "Epochs: 382\n",
            "discr loss =  0.3492276789177032 gan loss =  1.0306299577156703\n",
            "Epochs: 383\n",
            "discr loss =  0.3645279989356086 gan loss =  1.348103472164699\n",
            "Epochs: 384\n",
            "discr loss =  0.3560981821446192 gan loss =  1.811269584156218\n",
            "Epochs: 385\n",
            "discr loss =  0.3729336630730402 gan loss =  1.9169999304271879\n",
            "Epochs: 386\n",
            "discr loss =  0.34878294524692355 gan loss =  1.2447856182143802\n",
            "Epochs: 387\n",
            "discr loss =  0.35158810161408927 gan loss =  1.3438853138969058\n",
            "Epochs: 388\n",
            "discr loss =  0.33364542325337726 gan loss =  1.907451527459281\n",
            "Epochs: 389\n",
            "discr loss =  0.3591898495242709 gan loss =  1.4678466092972529\n",
            "Epochs: 390\n",
            "discr loss =  0.3527661157505853 gan loss =  1.6048014561335247\n",
            "Epochs: 391\n",
            "discr loss =  0.3395241761491412 gan loss =  1.8961146331968761\n",
            "Epochs: 392\n",
            "discr loss =  0.3477075965631576 gan loss =  1.594998524302528\n",
            "Epochs: 393\n",
            "discr loss =  0.3422024682873771 gan loss =  1.1029380758603413\n",
            "Epochs: 394\n",
            "discr loss =  0.35465171720300404 gan loss =  1.441810233252389\n",
            "Epochs: 395\n",
            "discr loss =  0.3427677310648419 gan loss =  2.0327496017728532\n",
            "Epochs: 396\n",
            "discr loss =  0.3504485104765211 gan loss =  2.069174039931524\n",
            "Epochs: 397\n",
            "discr loss =  0.34213986425172715 gan loss =  1.4834054566565014\n",
            "Epochs: 398\n",
            "discr loss =  0.36937076562926885 gan loss =  1.6883010154678708\n",
            "Epochs: 399\n",
            "discr loss =  0.35034990239711034 gan loss =  1.6893227753185092\n",
            "Epochs: 400\n",
            "discr loss =  0.35316737634795053 gan loss =  1.7518973492440724\n",
            "Epochs: 401\n",
            "discr loss =  0.35795525851703824 gan loss =  1.617674591995421\n",
            "Epochs: 402\n",
            "discr loss =  0.34301298005240305 gan loss =  1.9563013485499792\n",
            "Epochs: 403\n",
            "discr loss =  0.33352360413188026 gan loss =  1.9307715325128465\n",
            "Epochs: 404\n",
            "discr loss =  0.3530695672546114 gan loss =  0.779256685149102\n",
            "Epochs: 405\n",
            "discr loss =  0.33410196219171795 gan loss =  1.0138534818376814\n",
            "Epochs: 406\n",
            "discr loss =  0.31007943124998183 gan loss =  1.8133041631607782\n",
            "Epochs: 407\n",
            "discr loss =  0.3252948274215062 gan loss =  1.9482270933332897\n",
            "Epochs: 408\n",
            "discr loss =  0.32969715339796885 gan loss =  1.366597782997858\n",
            "Epochs: 409\n",
            "discr loss =  0.3804075675351279 gan loss =  0.9460347379956927\n",
            "Epochs: 410\n",
            "discr loss =  0.35581961274147034 gan loss =  1.5687053828012376\n",
            "Epochs: 411\n",
            "discr loss =  0.3411785889239538 gan loss =  1.8574783631733485\n",
            "Epochs: 412\n",
            "discr loss =  0.3336219681160791 gan loss =  1.1229246840590523\n",
            "Epochs: 413\n",
            "discr loss =  0.31926364699999493 gan loss =  1.6605427435466222\n",
            "Epochs: 414\n",
            "discr loss =  0.30392850935459137 gan loss =  1.9947802225748699\n",
            "Epochs: 415\n",
            "discr loss =  0.30123983323574066 gan loss =  1.9449608382724581\n",
            "Epochs: 416\n",
            "discr loss =  0.33205629601365044 gan loss =  1.8345606156757899\n",
            "Epochs: 417\n",
            "discr loss =  0.33258334795633954 gan loss =  1.314559464653333\n",
            "Epochs: 418\n",
            "discr loss =  0.3232323009343374 gan loss =  0.3130330791076024\n",
            "Epochs: 419\n",
            "discr loss =  0.3498273718924749 gan loss =  0.6849311604386285\n",
            "Epochs: 420\n",
            "discr loss =  0.33883920028096154 gan loss =  1.2718723189263117\n",
            "Epochs: 421\n",
            "discr loss =  0.34159559721038457 gan loss =  1.9374555519648962\n",
            "Epochs: 422\n",
            "discr loss =  0.346191589321409 gan loss =  1.9700620742071242\n",
            "Epochs: 423\n",
            "discr loss =  0.3395118677899951 gan loss =  2.0098526080449424\n",
            "Epochs: 424\n",
            "discr loss =  0.337209851259277 gan loss =  2.05551510765439\n",
            "Epochs: 425\n",
            "discr loss =  0.33531890951451804 gan loss =  1.3809647049222673\n",
            "Epochs: 426\n",
            "discr loss =  0.3271182889030093 gan loss =  1.4792835371834892\n",
            "Epochs: 427\n",
            "discr loss =  0.33418314655621845 gan loss =  1.8824614456721716\n",
            "Epochs: 428\n",
            "discr loss =  0.3666276548589979 gan loss =  2.0169530539285567\n",
            "Epochs: 429\n",
            "discr loss =  0.3333594167516345 gan loss =  1.566826601823171\n",
            "Epochs: 430\n",
            "discr loss =  0.33992603988874526 gan loss =  1.7614007393519084\n",
            "Epochs: 431\n",
            "discr loss =  0.3561957563672747 gan loss =  1.8218035641170682\n",
            "Epochs: 432\n",
            "discr loss =  0.36323719152382444 gan loss =  1.8865312792005993\n",
            "Epochs: 433\n",
            "discr loss =  0.35343417809123084 gan loss =  1.8015410502751668\n",
            "Epochs: 434\n",
            "discr loss =  0.34903604856559206 gan loss =  1.8698496023813884\n",
            "Epochs: 435\n",
            "discr loss =  0.3197046050003597 gan loss =  1.5169624444984255\n",
            "Epochs: 436\n",
            "discr loss =  0.3259275122767403 gan loss =  0.8995378939878373\n",
            "Epochs: 437\n",
            "discr loss =  0.312810806291444 gan loss =  1.7705949601672946\n",
            "Epochs: 438\n",
            "discr loss =  0.32720442754881723 gan loss =  2.0178693476177396\n",
            "Epochs: 439\n",
            "discr loss =  0.33707818388938904 gan loss =  0.905101817988214\n",
            "Epochs: 440\n",
            "discr loss =  0.33745829406238737 gan loss =  0.8035330800783067\n",
            "Epochs: 441\n",
            "discr loss =  0.33624132970968884 gan loss =  1.2740448032106673\n",
            "Epochs: 442\n",
            "discr loss =  0.3218586991230647 gan loss =  1.7672075487318493\n",
            "Epochs: 443\n",
            "discr loss =  0.3065173100857508 gan loss =  1.222874872031666\n",
            "Epochs: 444\n",
            "discr loss =  0.3106794236671357 gan loss =  0.7817128282927331\n",
            "Epochs: 445\n",
            "discr loss =  0.3437344219003405 gan loss =  1.7678965841020857\n",
            "Epochs: 446\n",
            "discr loss =  0.34979048938978285 gan loss =  1.746382372719901\n",
            "Epochs: 447\n",
            "discr loss =  0.34728857165291194 gan loss =  1.8005047979808988\n",
            "Epochs: 448\n",
            "discr loss =  0.3500350075108664 gan loss =  1.9655075413840157\n",
            "Epochs: 449\n",
            "discr loss =  0.35596265537398203 gan loss =  1.818885746456328\n",
            "Epochs: 450\n",
            "discr loss =  0.35808118397281286 gan loss =  1.8310180136135645\n",
            "Epochs: 451\n",
            "discr loss =  0.34284344741276335 gan loss =  1.6275684663227625\n",
            "Epochs: 452\n",
            "discr loss =  0.33533862233161926 gan loss =  1.7215328869365512\n",
            "Epochs: 453\n",
            "discr loss =  0.34703307776224046 gan loss =  1.7110542229243688\n",
            "Epochs: 454\n",
            "discr loss =  0.35117095495973316 gan loss =  1.6557137341726393\n",
            "Epochs: 455\n",
            "discr loss =  0.360014897726831 gan loss =  1.1615273895717801\n",
            "Epochs: 456\n",
            "discr loss =  0.33360609341235387 gan loss =  1.4677530754180181\n",
            "Epochs: 457\n",
            "discr loss =  0.3372888636021387 gan loss =  1.9748024202528454\n",
            "Epochs: 458\n",
            "discr loss =  0.3108144168342863 gan loss =  1.4393192444528853\n",
            "Epochs: 459\n",
            "discr loss =  0.3530694686231159 gan loss =  1.6350711981455486\n",
            "Epochs: 460\n",
            "discr loss =  0.34250364771911074 gan loss =  1.7246416466576713\n",
            "Epochs: 461\n",
            "discr loss =  0.32219292507285163 gan loss =  1.9154731716428484\n",
            "Epochs: 462\n",
            "discr loss =  0.34412904864265803 gan loss =  1.1256123319977807\n",
            "Epochs: 463\n",
            "discr loss =  0.3431268561454046 gan loss =  1.2665395992142814\n",
            "Epochs: 464\n",
            "discr loss =  0.3343184675489153 gan loss =  1.9684354634512038\n",
            "Epochs: 465\n",
            "discr loss =  0.3595975154922122 gan loss =  1.8998754138038272\n",
            "Epochs: 466\n",
            "discr loss =  0.33763668012051357 gan loss =  1.9721999281928653\n",
            "Epochs: 467\n",
            "discr loss =  0.35105575904959724 gan loss =  1.8905547630219233\n",
            "Epochs: 468\n",
            "discr loss =  0.33987170174008324 gan loss =  1.2721401907148815\n",
            "Epochs: 469\n",
            "discr loss =  0.3461353594348544 gan loss =  1.2619988577706474\n",
            "Epochs: 470\n",
            "discr loss =  0.37907389657838003 gan loss =  1.7359326566968645\n",
            "Epochs: 471\n",
            "discr loss =  0.3253053710574195 gan loss =  1.9740839515413557\n",
            "Epochs: 472\n",
            "discr loss =  0.3496385585694086 gan loss =  1.4230288040070307\n",
            "Epochs: 473\n",
            "discr loss =  0.3368180642525355 gan loss =  1.7234416007995605\n",
            "Epochs: 474\n",
            "discr loss =  0.34187220391773043 gan loss =  1.4732415363902138\n",
            "Epochs: 475\n",
            "discr loss =  0.3608252391928718 gan loss =  1.881003351438613\n",
            "Epochs: 476\n",
            "discr loss =  0.3341461888381413 gan loss =  1.7662564913431804\n",
            "Epochs: 477\n",
            "discr loss =  0.35659401686418624 gan loss =  1.6664320202100844\n",
            "Epochs: 478\n",
            "discr loss =  0.31487245644841877 gan loss =  0.7628530363241831\n",
            "Epochs: 479\n",
            "discr loss =  0.3176335323424566 gan loss =  1.7314893631708055\n",
            "Epochs: 480\n",
            "discr loss =  0.34108040091537295 gan loss =  1.7663556677954537\n",
            "Epochs: 481\n",
            "discr loss =  0.32624711309160503 gan loss =  1.8328270628338768\n",
            "Epochs: 482\n",
            "discr loss =  0.3193019770440601 gan loss =  1.9275022120702834\n",
            "Epochs: 483\n",
            "discr loss =  0.3088186198756808 gan loss =  1.875281606401716\n",
            "Epochs: 484\n",
            "discr loss =  0.3112412414380482 gan loss =  1.9102244263603574\n",
            "Epochs: 485\n",
            "discr loss =  0.3113917921270643 gan loss =  1.201764940505936\n",
            "Epochs: 486\n",
            "discr loss =  0.3249638087692715 gan loss =  0.2285123992533911\n",
            "Epochs: 487\n",
            "discr loss =  0.3383434131031945 gan loss =  0.5510058552026749\n",
            "Epochs: 488\n",
            "discr loss =  0.3463754597164336 gan loss =  1.138259958653223\n",
            "Epochs: 489\n",
            "discr loss =  0.36489324555510566 gan loss =  1.5584930578867595\n",
            "Epochs: 490\n",
            "discr loss =  0.34024167841389064 gan loss =  1.9654320932569957\n",
            "Epochs: 491\n",
            "discr loss =  0.34596700753484455 gan loss =  1.8774103323618572\n",
            "Epochs: 492\n",
            "discr loss =  0.3515546917915344 gan loss =  1.971087654431661\n",
            "Epochs: 493\n",
            "discr loss =  0.36010791999953135 gan loss =  1.271663262730553\n",
            "Epochs: 494\n",
            "discr loss =  0.34840173309757594 gan loss =  1.8266656739371163\n",
            "Epochs: 495\n",
            "discr loss =  0.3232345829407374 gan loss =  1.8662994418825423\n",
            "Epochs: 496\n",
            "discr loss =  0.33607560112362816 gan loss =  1.9285831564948672\n",
            "Epochs: 497\n",
            "discr loss =  0.31652313541798366 gan loss =  1.2436142691544123\n",
            "Epochs: 498\n",
            "discr loss =  0.3278120763245083 gan loss =  1.258042003427233\n",
            "Epochs: 499\n",
            "discr loss =  0.33542594952242716 gan loss =  1.4237313185419356\n",
            "Epochs: 500\n",
            "discr loss =  0.34390294835681007 gan loss =  1.4229063987731934\n",
            "Epochs: 501\n",
            "discr loss =  0.32615776643866584 gan loss =  1.6588073855354672\n",
            "Epochs: 502\n",
            "discr loss =  0.3351721742323467 gan loss =  1.6256045330138433\n",
            "Epochs: 503\n",
            "discr loss =  0.3320247381925583 gan loss =  1.7146240756625222\n",
            "Epochs: 504\n",
            "discr loss =  0.33401509693690706 gan loss =  1.8913711139133997\n",
            "Epochs: 505\n",
            "discr loss =  0.3076157931770597 gan loss =  1.6787245443889074\n",
            "Epochs: 506\n",
            "discr loss =  0.3498603162311372 gan loss =  1.33667587240537\n",
            "Epochs: 507\n",
            "discr loss =  0.35337690441381364 gan loss =  0.8647556077866327\n",
            "Epochs: 508\n",
            "discr loss =  0.3516980707645416 gan loss =  1.1267694092932201\n",
            "Epochs: 509\n",
            "discr loss =  0.35946553023088545 gan loss =  1.6202949030058724\n",
            "Epochs: 510\n",
            "discr loss =  0.3365909286907741 gan loss =  1.6807654329708643\n",
            "Epochs: 511\n",
            "discr loss =  0.3293568520318894 gan loss =  1.3843920287631808\n",
            "Epochs: 512\n",
            "discr loss =  0.33774435094424654 gan loss =  1.919011536098662\n",
            "Epochs: 513\n",
            "discr loss =  0.34104178774924504 gan loss =  1.9636465367816744\n",
            "Epochs: 514\n",
            "discr loss =  0.35762913879894076 gan loss =  1.7136591672897339\n",
            "Epochs: 515\n",
            "discr loss =  0.375320953982217 gan loss =  1.5885819083168393\n",
            "Epochs: 516\n",
            "discr loss =  0.33913423333849224 gan loss =  1.8246109655925207\n",
            "Epochs: 517\n",
            "discr loss =  0.33216349070980433 gan loss =  1.408783222947802\n",
            "Epochs: 518\n",
            "discr loss =  0.3396836831456139 gan loss =  1.4019324268613542\n",
            "Epochs: 519\n",
            "discr loss =  0.33644470288639977 gan loss =  1.7475326118015109\n",
            "Epochs: 520\n",
            "discr loss =  0.34887548145793734 gan loss =  1.8482526597522555\n",
            "Epochs: 521\n",
            "discr loss =  0.34292618007886977 gan loss =  1.7539239100047521\n",
            "Epochs: 522\n",
            "discr loss =  0.3393064857948394 gan loss =  1.5505658161072504\n",
            "Epochs: 523\n",
            "discr loss =  0.34417639176050824 gan loss =  1.907830312138512\n",
            "Epochs: 524\n",
            "discr loss =  0.3246925799619584 gan loss =  1.8205646446772985\n",
            "Epochs: 525\n",
            "discr loss =  0.34079953176634653 gan loss =  1.7063308982622056\n",
            "Epochs: 526\n",
            "discr loss =  0.330019059635344 gan loss =  1.5881280927431016\n",
            "Epochs: 527\n",
            "discr loss =  0.2959885923635392 gan loss =  1.402407700107211\n",
            "Epochs: 528\n",
            "discr loss =  0.3124762248425257 gan loss =  1.837453598067874\n",
            "Epochs: 529\n",
            "discr loss =  0.2969284774292083 gan loss =  1.8826802741913569\n",
            "Epochs: 530\n",
            "discr loss =  0.3065221295470283 gan loss =  1.9386677174341111\n",
            "Epochs: 531\n",
            "discr loss =  0.31111874183019 gan loss =  1.852791434242612\n",
            "Epochs: 532\n",
            "discr loss =  0.33094178707826705 gan loss =  1.893357515335083\n",
            "Epochs: 533\n",
            "discr loss =  0.3230016302494776 gan loss =  1.933625334785098\n",
            "Epochs: 534\n",
            "discr loss =  0.3282636836880729 gan loss =  1.0757825388794853\n",
            "Epochs: 535\n",
            "discr loss =  0.3472886582215627 gan loss =  0.7035238969893682\n",
            "Epochs: 536\n",
            "discr loss =  0.31181497162296656 gan loss =  1.5968017578125\n",
            "Epochs: 537\n",
            "discr loss =  0.35866554152397884 gan loss =  1.5391877321969896\n",
            "Epochs: 538\n",
            "discr loss =  0.3400289671761649 gan loss =  1.6017346041543143\n",
            "Epochs: 539\n",
            "discr loss =  0.3376709818840027 gan loss =  1.5439724581582206\n",
            "Epochs: 540\n",
            "discr loss =  0.3274161120255788 gan loss =  1.7895420732952299\n",
            "Epochs: 541\n",
            "discr loss =  0.34845427175362903 gan loss =  1.3697773700668698\n",
            "Epochs: 542\n",
            "discr loss =  0.34438667198022205 gan loss =  1.9203313645862399\n",
            "Epochs: 543\n",
            "discr loss =  0.343793694462095 gan loss =  1.5849114713214694\n",
            "Epochs: 544\n",
            "discr loss =  0.340429166952769 gan loss =  1.9379925103414626\n",
            "Epochs: 545\n",
            "discr loss =  0.3051792283852895 gan loss =  2.0760178736277988\n",
            "Epochs: 546\n",
            "discr loss =  0.32130788337616695 gan loss =  1.3431907452288128\n",
            "Epochs: 547\n",
            "discr loss =  0.35048134554000127 gan loss =  1.2897830719039554\n",
            "Epochs: 548\n",
            "discr loss =  0.34730137458869387 gan loss =  1.8381354808807373\n",
            "Epochs: 549\n",
            "discr loss =  0.34960191874277025 gan loss =  1.786197719119844\n",
            "Epochs: 550\n",
            "discr loss =  0.3486494833514804 gan loss =  1.6949587492715745\n",
            "Epochs: 551\n",
            "discr loss =  0.3454108117591767 gan loss =  1.4530036790030343\n",
            "Epochs: 552\n",
            "discr loss =  0.3183292540765944 gan loss =  1.5050746656599499\n",
            "Epochs: 553\n",
            "discr loss =  0.33437974963869366 gan loss =  2.0255004394622076\n",
            "Epochs: 554\n",
            "discr loss =  0.34865023976280574 gan loss =  1.9108725842975436\n",
            "Epochs: 555\n",
            "discr loss =  0.3629127329304105 gan loss =  1.9069418169203258\n",
            "Epochs: 556\n",
            "discr loss =  0.3629320952154341 gan loss =  1.6631210588273548\n",
            "Epochs: 557\n",
            "discr loss =  0.33666315532865976 gan loss =  1.6353619950158256\n",
            "Epochs: 558\n",
            "discr loss =  0.36985592189289274 gan loss =  1.8226979005904425\n",
            "Epochs: 559\n",
            "discr loss =  0.3427289000579289 gan loss =  1.8978224084490822\n",
            "Epochs: 560\n",
            "discr loss =  0.3599183275586083 gan loss =  1.6058641728900729\n",
            "Epochs: 561\n",
            "discr loss =  0.34159564546176363 gan loss =  1.7534898178918021\n",
            "Epochs: 562\n",
            "discr loss =  0.3415446813617434 gan loss =  1.8671782641183763\n",
            "Epochs: 563\n",
            "discr loss =  0.32929928104082745 gan loss =  1.9332417192913236\n",
            "Epochs: 564\n",
            "discr loss =  0.33531249775773003 gan loss =  1.7029491662979126\n",
            "Epochs: 565\n",
            "discr loss =  0.34572656523613704 gan loss =  1.529805580774943\n",
            "Epochs: 566\n",
            "discr loss =  0.3375340167965208 gan loss =  1.8717437244596935\n",
            "Epochs: 567\n",
            "discr loss =  0.34635771101429347 gan loss =  1.4590218861897786\n",
            "Epochs: 568\n",
            "discr loss =  0.34165889734313604 gan loss =  1.8430979876291185\n",
            "Epochs: 569\n",
            "discr loss =  0.35474224885304767 gan loss =  1.6280546415419805\n",
            "Epochs: 570\n",
            "discr loss =  0.3747860377743131 gan loss =  1.8007338898522514\n",
            "Epochs: 571\n",
            "discr loss =  0.35206070116588045 gan loss =  1.5583241212935675\n",
            "Epochs: 572\n",
            "discr loss =  0.3337408992506209 gan loss =  1.7727474030994235\n",
            "Epochs: 573\n",
            "discr loss =  0.3686232552641914 gan loss =  1.697805540902274\n",
            "Epochs: 574\n",
            "discr loss =  0.36892756252061754 gan loss =  1.923679618608384\n",
            "Epochs: 575\n",
            "discr loss =  0.3398235397679465 gan loss =  1.8488732633136569\n",
            "Epochs: 576\n",
            "discr loss =  0.34501327148505617 gan loss =  1.784582013175601\n",
            "Epochs: 577\n",
            "discr loss =  0.34552493478570667 gan loss =  1.6211594797316051\n",
            "Epochs: 578\n",
            "discr loss =  0.3746027442671004 gan loss =  1.814913346653893\n",
            "Epochs: 579\n",
            "discr loss =  0.33582665026187897 gan loss =  1.8684796605791365\n",
            "Epochs: 580\n",
            "discr loss =  0.35997521735372995 gan loss =  1.5680925590651376\n",
            "Epochs: 581\n",
            "discr loss =  0.3386283985206059 gan loss =  1.6619473752521334\n",
            "Epochs: 582\n",
            "discr loss =  0.34649084153629484 gan loss =  1.7982224169231595\n",
            "Epochs: 583\n",
            "discr loss =  0.3361352816933677 gan loss =  1.5900448049817766\n",
            "Epochs: 584\n",
            "discr loss =  0.3545479107470739 gan loss =  1.343627325126103\n",
            "Epochs: 585\n",
            "discr loss =  0.34994102943511235 gan loss =  1.6842159941082908\n",
            "Epochs: 586\n",
            "discr loss =  0.3390635642267409 gan loss =  1.9526792537598383\n",
            "Epochs: 587\n",
            "discr loss =  0.32890857188474565 gan loss =  1.8922828208832514\n",
            "Epochs: 588\n",
            "discr loss =  0.3250535144692376 gan loss =  1.6350419634864444\n",
            "Epochs: 589\n",
            "discr loss =  0.34575967419715153 gan loss =  1.6143589842887152\n",
            "Epochs: 590\n",
            "discr loss =  0.3752395368757702 gan loss =  1.619344223113287\n",
            "Epochs: 591\n",
            "discr loss =  0.33129092979998814 gan loss =  1.7712115106128512\n",
            "Epochs: 592\n",
            "discr loss =  0.34647312263647717 gan loss =  1.8755990777696883\n",
            "Epochs: 593\n",
            "discr loss =  0.3601280124414535 gan loss =  1.9697641815458025\n",
            "Epochs: 594\n",
            "discr loss =  0.35844701244717553 gan loss =  1.783656739053272\n",
            "Epochs: 595\n",
            "discr loss =  0.33391482276575907 gan loss =  1.5682136558351063\n",
            "Epochs: 596\n",
            "discr loss =  0.35688172564620063 gan loss =  1.6309423106057304\n",
            "Epochs: 597\n",
            "discr loss =  0.34835584248815266 gan loss =  1.7944005387169975\n",
            "Epochs: 598\n",
            "discr loss =  0.35390591621398926 gan loss =  1.8724663654963176\n",
            "Epochs: 599\n",
            "discr loss =  0.33011854759284426 gan loss =  1.7904078279222762\n",
            "Epochs: 600\n",
            "discr loss =  0.3434834615105674 gan loss =  1.774267321541196\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
